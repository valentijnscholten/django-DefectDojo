

























[{"body":"DefectDojo Basics Terms There are several terms that will be helpful to understand as you work with DefectDojo\nProducts This is the name of any project, program, team, or company that you are currently testing.\nExamples\n Wordpress Internal wiki Slack  Product types These can be business unit divisions, different offices or locations, or any other logical way of distinguishing \"types\" of products.\nExamples\n Internal / 3rd party Main company / Acquisition San Francisco / New York offices  Engagements Engagements are moments in time when testing is taking place. They are associated with a name for easy reference, a time line, a lead (the user account of the main person conducting the testing), a test strategy, and a status.\nExamples\n Beta Quarterly PCI Scan Release Version X  Test Types These can be any sort of distinguishing characteristic about the type of testing that was done during an Engagement.\nExamples\n Functional Security Nessus Scan API test  Environments These describe the environment that was tested during a particular Engagement.\nExamples\n Production Staging Stable  ","categories":"","description":"","excerpt":"DefectDojo Basics Terms There are several terms that will be helpful …","ref":"/django-DefectDojo/basics/about/","tags":"","title":"About DefectDojo"},{"body":"DefectDojo has the ability to import reports from other security tools.\nSecurity Tools Acunetix Scanner XML format\nAnchore-Engine JSON vulnerability report generated by anchore-cli tool, using a command like anchore-cli --json image vuln \u003cimage:tag\u003e all\nAqua JSON report format.\nAnchore Grype Anchore Grype JSON report format generated with -o json option.\ngrype defectdojo/defectdojo-django:1.13.1 -o json \u003e many_vulns.json Arachni Scanner Arachni Web Scanner (http://arachni-scanner.com/wiki)\nReports are generated with arachni_reporter tool this way:\narachni_reporter --reporter 'json' js.com.afr AppSpider (Rapid7) Use the VulnerabilitiesSummary.xml file found in the zipped report download.\nAWS Security Hub The JSON output from AWS Security Hub exported with the aws securityhub get-findings (https://docs.aws.amazon.com/cli/latest/reference/securityhub/get-findings.html) command.\nAWS Scout2 Scanner JS file in scout2-report/inc-awsconfig/aws_config.js.\nAWS Prowler Scanner Prowler file can be imported as a CSV file (-M csv).\nBandit JSON report format\nBlackduck Hub 2 options:\n Import the zip file as can be created by Blackduck export. The zip file must contain the security.csv and files.csv in order to produce findings that bear file locations information. Import a single security.csv file. Findings will not have any file location information.  Brakeman Scan Import Brakeman Scanner findings in JSON format.\nBugcrowd Import Bugcrowd results in CSV format.\nBundler-Audit Import the text output generated with bundle-audit check\nBurp XML When the Burp report is generated, the recommended option is Base64 encoding both the request and response fields - e.g. check the box that says \"Base64-encode requests and responses\". These fields will be processed and made available in the 'Finding View' page.\nBurp Enterprise Scan Import HTML reports from Burp Enterprise Edition\nCCVS Report Import JSON reports from [CCVS API](https://github.com/William-Hill-Online/CCVS-API)\nCheckov Report Import JSON reports of Infrastructure as Code vulnerabilities.\nClair Scan Import JSON reports of Docker image vulnerabilities.\nClair Klar Scan Import JSON reports of Docker image vulnerabilities from clair klar client.\nCobalt.io Scan CSV Report\nCoverity API Export Coverity API view data in JSON format (/api/viewContents/issues endpoint).\nCurrently these columns are mandatory:\n displayType (Type in the UI) displayImpact (Impact in the UI) status (Status in the UI) firstDetected (First Detected in the UI)  Other supported attributes: cwe, displayFile, occurrenceCount and firstDetected\nCrashtest Security Import JSON Report Import XML Report in JUnit Format\nCredScan Report Import CSV credential scanner reports\nContrast Scanner CSV Report\nCheckmarx  Checkmarx Scan, Checkmarx Scan detailed: XML report from Checkmarx SAST (source code analysis) Checkmarx OSA: json report from Checkmarx Open Source Analysis (dependencies analysis)  To generate the OSA report using Checkmarx CLI: ./runCxConsole.sh OsaScan -v -CxServer \u003c...\u003e -CxToken \u003c..\u003e -projectName \u003c...\u003e -enableOsa -OsaLocationPath \u003clib_folder\u003e -OsaJson \u003coutput_folder\u003e\nThat will generate three files, two of which are needed for defectdojo. Build the file for defectdojo with the jq utility: jq -s . CxOSAVulnerabilities.json CxOSALibraries.json\nChoctaw Hog parser From: https://github.com/newrelic/rusty-hog Import the JSON output.\nCycloneDX CycloneDX is a lightweight software bill of materials (SBOM) standard designed for use in application security contexts and supply chain component analysis.\nFrom: https://www.cyclonedx.org/\nExample with Anchore Grype:\n./grype defectdojo/defectdojo-django:1.13.1 -o cyclonedx \u003e report.xml Example with cyclonedx-bom tool:\npip install cyclonedx-bom cyclonedx-py Usage: cyclonedx-py [OPTIONS] Options: -i \u003cpath\u003e - the alternate filename to a frozen requirements.txt -o \u003cpath\u003e - the bom file to create -j - generate JSON instead of XML DawnScanner Import report in JSON generated with -j option\nDependency Check OWASP Dependency Check output can be imported in Xml format.\nDependency Track Dependency Track has implemented a DefectDojo integration. Information about how to configure the integration is documented here: https://docs.dependencytrack.org/integrations/defectdojo/\nAlternatively, the Finding Packaging Format (FPF) from OWASP Dependency Track can be imported in JSON format. See here for more info on this JSON format: https://docs.dependencytrack.org/integrations/file-formats/\nDrHeader Import of JSON report from https://github.com/Santandersecurityresearch/DrHeader\nESLint ESLint Json report format (-f json)\nFortify Import Findings from XML file format.\nGeneric Findings Import Import Generic findings in CSV format.\nHadolint Hadolint Dockerfile scan in json format.\nHarbor Vulnerability Import findings from Harbor registry container scan: https://github.com/goharbor/harbor\nJFrogXRay Import the JSON format for the \"Security Export\" file.\nGosec Scanner Import Gosec Scanner findings in JSON format.\nGitleaks Import Gitleaks findings in JSON format.\nGitLab SAST Report Import SAST Report vulnerabilities in JSON format: https://docs.gitlab.com/ee/user/application_security/sast/#reports-json-format\nGitLab Dependency Scanning Report Import Dependency Scanning Report vulnerabilities in JSON format: https://docs.gitlab.com/ee/user/application_security/dependency_scanning/#reports-json-format\nGithub Vulnerability Import findings from Github vulnerability scan: https://help.github.com/en/github/managing-security-vulnerabilities\nGithub v4 graphql query to fetch data:\nquery getVulnerabilitiesByOwner($owner: String!) { search(query: $owner, type: REPOSITORY, first: 100) { nodes { ... on Repository { name\u003cbr/\u003e vulnerabilityAlerts(last: 100) { nodes { id\u003cbr/\u003e securityVulnerability { severity\u003cbr/\u003e package { name } advisory { description\u003cbr/\u003e summary\u003cbr/\u003e identifiers { type\u003cbr/\u003e value } references { url } } } } } } } } } HuskyCI Report Import JSON reports from HuskyCI\nIBM AppScan DAST XML file from IBM App Scanner.\nImmuniweb Scan XML Scan Result File from Immuniweb Scan.\nIntSights Report IntSights Threat Command is a commercial Threat Intelligence platform that monitors both the open and dark web to identify threats for the Assets you care about (Domain Names, IP addresses, Brand Names, etc.).\nManual Import Use the Export CSV feature in the IntSights Threat Command GUI to create an IntSights Alerts.csv file. This CSV file can then be imported into Defect Dojo.\nAutomated Import The IntSights get-complete-alert API only returns details for a single alert. To automate the process, individually fetch details for each alert and append to a list. The list is then saved as the value for the key “Alerts”. This JSON object can then be imported into Defect Dojo.\nExample:\n{ \"Alerts\":[ { \"_id\":\"5c80egf83b4a3900078b6be6\", \"Details\":{ \"Source\":{ \"URL\":\"https://www.htbridge.com/websec/?id=ABCDEF\", \"Date\":\"2018-03-08T00:01:02.622Z\", \"Type\":\"Other\", \"NetworkType\":\"ClearWeb\" }, \"Images\":[ \"5c80egf833963a40007e01e8d\", \"5c80egf833b4a3900078b6bea\", \"5c80egf834626bd0007bd64db\" ], \"Title\":\"HTTP headers weakness in example.com web server\", \"Tags\":[], \"Type\":\"ExploitableData\", \"Severity\":\"Critical\", \"SubType\":\"VulnerabilityInTechnologyInUse\", \"Description\":\"X-XSS-PROTECTION and CONTENT-SECURITY-POLICY headers were not sent by the server, which makes it vulnerable for various attack vectors\" }, \"Assignees\":[ \"5c3c8f99903dfd0006ge5e61\" ], \"FoundDate\":\"2018-03-08T00:01:02.622Z\", \"Assets\":[ { \"Type\":\"Domains\", \"Value\":\"example.com\" } ], \"TakedownStatus\":\"NotSent\", \"IsFlagged\":false, \"UpdateDate\":\"2018-03-08T00:01:02.622Z\", \"RelatedIocs\":[], \"RelatedThreatIDs\":[], \"Closed\":{ \"IsClosed\":false } } ] }  Kiuwan Scanner Import Kiuwan Scan in CSV format. Export as CSV Results on Kiuwan.\nkube-bench Scanner Import JSON reports of Kubernetes CIS benchmark scans.\nMicrofocus Webinspect Scanner Import XML report\nMobSF Scanner Export a JSON file using the API, api/v1/report_json.\nMozilla Observatory Scanner Import JSON report.\nNessus (Tenable) Reports can be imported in the CSV, and .nessus (XML) report formats.\nNetsparker Vulnerabilities List - JSON report\nNexpose XML 2.0 (Rapid7) Use the full XML export template from Nexpose.\nNikto Nikto web server scanner - https://cirt.net/Nikto2\nThe current parser support 3 sources:\n XML output (old) new XML output (with nxvmlversion=\"1.2\" type) JSON output  See: https://github.com/sullo/nikto\nNmap XML output (use -oX)\nNode JS Scan Node JS Scan output file can be imported in JSON format.\nNode Security Platform Node Security Platform (NSP) output file can be imported in JSON format.\nNPM Audit Node Package Manager (NPM) Audit plugin output file can be imported in JSON format. Only imports the 'advisories' subtree.\nOpenscap Vulnerability Scan Import Openscap Vulnerability Scan in XML formats.\nOpenVAS CSV Import OpenVAS Scan in CSV format. Export as CSV Results on OpenVAS.\nOssIndex Devaudit Import JSON formatted output from [OSSIndex Devaudit](https://github.com/sonatype-nexus-community/DevAudit).\nOss Review Toolkit Import ORT Evaluated model reporter in JSON Format. (Example)[https://github.com/DefectDojo/sample-scan-files/blob/master/ort/evaluated-model-reporter-output.json]\nPHP Security Audit v2 Import PHP Security Audit v2 Scan in JSON format.\nPHP Symfony Security Checker Import results from the PHP Symfony Security Checker.\nProbely Synchronize Probely Plus findings with DefectDojo.\nTo setup this integration set the DefectDojo URL and API key on the Integrations page on Probely. Then, select which Product, Engagement, and, optionally, the Test you want to synchronize to. The API key needs to belong to a staff user.\nWorks with DefectDojo 1.5.x and 1.6.x. Probely also supports non-public DefectDojo instances.\nFor detailed instructions on how to configure Probely and DefectDojo, see https://help.probely.com/en/articles/3811515-how-to-integrate-probely-with-defectdojo\nQualys Scan Qualys output files can be imported in API XML format. Qualys output files can be imported in WebGUI XML format.\nQualys Webapp Scan Qualys WebScan output files can be imported in XML format.\nRetire.js Retire.js JavaScript scan (--js) output file can be imported in JSON format.\nRisk Recon API Importer Import findings from Risk Recon via the API. Configure your own JSON report as follows\n{ \"url_endpoint\": \"https://api.riskrecon.com/v1\", \"api_key\": \"you-api-key\", \"companies\": [ { \"name\": \"Company 1\", \"filters\": { \"domain_name\": [], \"ip_address\": [\"127.0.0.1\"], \"host_name\": [\"localhost\"], \"asset_value\": [], \"severity\": [\"critical\", \"high\"], \"priority\": [], \"hosting_provider\": [], \"country_name\": [] } }, { \"name\": \"Company 2\", \"filters\": { \"ip_address\": [\"0.0.0.0\"] } } ], \"filters\": { \"domain_name\": [], \"ip_address\": [], \"host_name\": [], \"asset_value\": [], \"severity\": [\"critical\"], \"priority\": [], \"hosting_provider\": [], \"country_name\": [] } }  More than one company finding list can be queried with it's own set of filters. Company 1 shows all available fitlers, while Company 2 shows that empty filters need not be present. To query all companies in your Risk Recon instance, simple remove the \"companies\" field entirely. If the \"companies\" field is not present, and filtering is still requested, the \"filters\" field can be used to filter all findings across all companies. It carries the same behavior as the company filters. The \"filters\" field is disregarded in the prescense of the \"companies\" field. Removing both fields will allow retrieval of all findings in the Risk Recon instance.  Safety Scan Safety scan (--json) output file can be imported in JSON format.\nSARIF OASIS Static Analysis Results Interchange Format (SARIF). SARIF is supported by many tools. More details about the format here: https://www.oasis-open.org/committees/tc_home.php?wg_abbrev=sarif\nScoutSuite Multi-Cloud security auditing tool. It uses APIs exposed by cloud providers. Scan results are located at scan-reports/scoutsuite-results/scoutsuite\\_\\*.json files. Multiple scans will create multiple files if they are runing agains different Cloud projects. See https://github.com/nccgroup/ScoutSuite\nSKF Scan Output of SKF Sprint summary export.\nSnyk Snyk output file (snyk test --json \u003e snyk.json) can be imported in JSON format.\nSonarQube Scan (Aggregates findings per cwe, title, description, file_path.) SonarQube output file can be imported in HTML format.\nTo generate the report, see https://github.com/soprasteria/sonar-report\nVersion: \u003e= 1.1.0\nSonarQube Scan Detailed (Import all findings from SonarQube html report.) SonarQube output file can be imported in HTML format.\nTo generate the report, see https://github.com/soprasteria/sonar-report\nVersion: \u003e= 1.1.0\nSonarQube API Import SonarQube API will be accessed to gather the report. No report file required.\nFollow below steps to setup API Import:\n Configure the Sonarqube Authentication details by navigating to Configuration-\u003eTool Configuration. Note the url should be in the formation of \u003chttp(s)://\u003e\u003csonarqube_hostname\u003e/api. Select the tool type to SonarQube. By default tool will import vulnerabilities only, but additional filters can be setup using Extras field separated by commas (e.g. BUG,VULNERABILITY,CODE_SMELL) In the Product settings fill the details for the SonarQube Project Key (Key name can be found by navigating to a specific project and selecting the value from the url \u003chttp(s)://\u003e\u003csonarqube_host\u003e/dashboard?id=\u003ckey_name\u003e Once all of the above setting are made, the API Import should be able to auto import all vulnerability information from the SonarQube instance.  NOTE: If https is in use for the SonarQube than certificate should be trusted by DD instance.\nSpotBugs XML report of textui cli.\nSonatype JSON output.\nSSL Labs JSON Output of ssllabs-scan cli.\nSslscan Import XML output of sslscan report.\nSslyze Scan XML report of SSLyze version 2 scan\nSSLyze 3 Scan (JSON) JSON report of SSLyze version 3 scan\nTestssl Scan Import CSV output of testssl scan report.\nTrivy JSON report of trivy scanner.\nTrufflehog JSON Output of Trufflehog.\nTrustwave CSV output of Trustwave vulnerability scan.\nTwistlock JSON output of the twistcli tool. Example:\n./twistcli images scan \u003cREGISTRY/REPO:TAG\u003e --address https://\u003cSECURE_URL_OF_TWISTLOCK_CONSOLE\u003e --user \u003cUSER\u003e --details --output-file=\u003cPATH_TO_SAVE_JSON_FILE\u003e The CSV output from the UI is now also accepted.\nVisual Code Grepper (VCG) VCG output can be imported in CSV or Xml formats.\nVeracode Detailed XML Report\nWapiti Scan Import XML report.\nWhitesource Scan Import JSON report\nWpscan Scanner Import JSON report.\nWfuzz JSON importer Import the result of Wfuzz (https://github.com/xmendez/wfuzz) if you export in JSON the result (wfuzz -o json -f myJSONReport.json,json).\nThe return code matching are directly put in Severity as follow(this is hardcoded in the parser actually).\n   HTTP Return Code Severity     200 High   401 Medium   403 Medium   407 Medium   500 Low    Xanitizer Import XML findings list report, preferably with parameter 'generateDetailsInFindingsListReport=true'.\nZed Attack Proxy ZAP XML report format.\nImport and reimport in DefectDojo The importers analyze each report and create new Findings for each item reported. DefectDojo collapses duplicate Findings by capturing the individual hosts vulnerable.\nAdditionally, DefectDojo allows for re-imports of previously uploaded reports. DefectDojo will attempt to capture the deltas between the original and new import and automatically add or mitigate findings as appropriate.\nBulk import via CSV Bulk import of findings can be done using a CSV file with the following column headers:\n Date Date of the finding in mm/dd/yyyy format. Title: Title of the finding CweId Cwe identifier, must be an integer value. Url: Url associated with the finding. Severity: Severity of the finding. Must be one of Info, Low, Medium, High, or Critical. Description: Description of the finding. Can be multiple lines if enclosed in double quotes. Mitigation: Possible Mitigations for the finding. Can be multiple lines if enclosed in double quotes. Impact: Detailed impact of the finding. Can be multiple lines if enclosed in double quotes. References: References associated with the finding. Can be multiple lines if enclosed in double quotes. Active: Indicator if the finding is active. Must be empty, True or False Verified: Indicator if the finding has been verified. Must be empty, True, or False FalsePositive: Indicator if the finding is a false positive. Must be True, or False. Duplicate: Indicator if the finding is a duplicate. Must be True, or False.  ","categories":"","description":"","excerpt":"DefectDojo has the ability to import reports from other security …","ref":"/django-DefectDojo/integrations/import/","tags":"","title":"Import Reports"},{"body":"Docker Compose install (recommended)  Go to https://github.com/DefectDojo/django-DefectDojo Select the appropriate branch you're working on Instructions in the DOCKER.md file at the root of the repository.  Kubernetes install  Go to https://github.com/DefectDojo/django-DefectDojo Select the appropriate branch you're working on Instructions in the KUBERNETES.md file at the root of the repository.  Customizing settings See Configuration\n","categories":"","description":"","excerpt":"Docker Compose install (recommended)  Go to …","ref":"/django-DefectDojo/running/getting-started/","tags":"","title":"Installation"},{"body":"","categories":"","description":"","excerpt":"","ref":"/django-DefectDojo/basics/","tags":"","title":"Basics"},{"body":"","categories":"","description":"","excerpt":"","ref":"/django-DefectDojo/integrations/","tags":"","title":"Integrations"},{"body":"DefectDojo's API is created using Django Rest Framework. The documentation of each endpoint is available within each DefectDojo installation at /api/v2/doc/ and can be accessed by choosing the API v2 Docs link on the user drop down menu in the header.\nThe documentation is generated using Django Rest Framework Swagger, and is interactive.\nTo interact with the documentation, a valid Authorization header value is needed. Visit the /api/v2/key/ view to generate your API Key (Token \u003capi_key\u003e) and copy the header value provided.\nReturn to the /api/v2/doc/ and click on Authorize to open the Authorization form. Paste your key in the form field provided and click on the Authorize button. Your authorization header value will be captured and used for all requests.\nEach section allows you to make calls to the API and view the Request URL, Response Body, Response Code and Response Headers.\nAuthentication The API uses header authentication with API key. The format of the header should be: :\nAuthorization: Token \u003capi.key\u003e  For example: :\nAuthorization: Token c8572a5adf107a693aa6c72584da31f4d1f1dcff  Sample Code Here are some simple python examples and their results produced against the /users endpoint: :\nimport requests url = 'http://127.0.0.1:8000/api/v2/users' headers = {'content-type': 'application/json', 'Authorization': 'Token c8572a5adf107a693aa6c72584da31f4d1f1dcff'} r = requests.get(url, headers=headers, verify=True) # set verify to False if ssl cert is self-signed for key, value in r.__dict__.iteritems(): print key print value print '------------------' This code will return the list of all the users defined in DefectDojo. The json object result looks like : :\n[ { \"first_name\": \"Tyagi\", \"id\": 22, \"last_login\": \"2019-06-18T08:05:51.925743\", \"last_name\": \"Paz\", \"username\": \"dev7958\" }, { \"first_name\": \"saurabh\", \"id\": 31, \"last_login\": \"2019-06-06T11:44:32.533035\", \"last_name\": \"\", \"username\": \"saurabh.paz\" } ] Here is another example against the /users endpoint, this time we will filter the results to include only the users whose user name includes jay:\nimport requests url = 'http://127.0.0.1:8000/api/v2/users/?username__contains=jay' headers = {'content-type': 'application/json', 'Authorization': 'Token c8572a5adf107a693aa6c72584da31f4d1f1dcff'} r = requests.get(url, headers=headers, verify=True) # set verify to False if ssl cert is self-signed for key, value in r.__dict__.iteritems(): print key print value print '------------------' The json object result is: :\n[ { \"first_name\": \"Jay\", \"id\": 22, \"last_login\": \"2015-10-28T08:05:51.925743\", \"last_name\": \"Paz\", \"username\": \"jay7958\" }, { \"first_name\": \"\", \"id\": 31, \"last_login\": \"2015-10-13T11:44:32.533035\", \"last_name\": \"\", \"username\": \"jay.paz\" } ] See Django Rest Framework's documentation on interacting with an API for additional examples and tips.\nManually calling the API Tools like Postman can be used for testing the API.\nExample for importing a scan result:\n  Verb: POST\n  URI: http://localhost:8080/api/v2/import-scan/\n  Headers tab:\n add the authentication header  Key: Authorization Value: Token c8572a5adf107a693aa6c72584da31f4d1f1dcff      Body tab\n select \"form-data\", click \"bulk edit\". Example for a ZAP scan:    engagement:3 verified:true active:true lead:1 tags:test scan_date:2019-04-30 scan_type:ZAP Scan minimum_severity:Info skip_duplicates:true close_old_findings:false    Body tab\n Click \"Key-value\" edit Add a \"file\" parameter of type \"file\". This will trigger multi-part form data for sending the file content Browse for the file to upload    Click send\n  ","categories":"","description":"","excerpt":"DefectDojo's API is created using Django Rest Framework. The …","ref":"/django-DefectDojo/integrations/api-v2-docs/","tags":"","title":"DefectDojo API v2"},{"body":"DefectDojo attempts to simplify how users interact with the system by minimizing the number of objects it defines. The definition for each as well as sample usages is below.\nProduct Types Product types represent the top level model, these can be business unit divisions, different offices or locations, development teams, or any other logical way of distinguishing \"types\" of products.\n Examples:  IAM Team Internal / 3rd Party Main company / Acquisition San Francisco / New York offices    Products This is the name of any project, program, or product that you are currently testing.\n  Examples:\n Wordpress Internal wiki Slack    Environments These describe the environment that was tested in a particular Test.\n  Examples\n Production Staging Stable Development    Engagements Engagements are moments in time when testing is taking place. They are associated with a name for easy reference, a time line, a lead (the user account of the main person conducting the testing), a test strategy, and a status. Engagement consists of two types: Interactive and CI/CD. An interactive engagement is typically an engagement conducted by an engineer, where findings are usually uploaded by the engineer. A CI/CD engagement, as it's name suggests, is for automated integration with a CI/CD pipeline.\n  Examples\n Beta Quarterly PCI Scan Release Version X    Test Types These can be any sort of distinguishing characteristic about the type of testing that was done in an Engagement.\n Examples  Functional Security Nessus Scan API test Static Analysis    Test Tests are a grouping of activities conducted by engineers to attempt to discover flaws in a product. Tests represent an instance of a Test Type\n  a moment in time when the product is being analyzed. Tests are bundled within engagements, have a start and end date and are defined by a test type.\n  Examples\n Burp Scan from Oct. 29, 2015 to Oct. 29, 2015 Nessus Scan from Oct. 31, 2015 to Oct. 31, 2015 API Test from Oct. 15, 2015 to Oct. 20, 2015    Finding A finding represents a flaw discovered while testing. It can be categorized with severities of Critical, High, Medium, Low, and Informational (Info).\n  Examples\n OpenSSL 'ChangeCipherSpec' MiTM Potential Vulnerability Web Application Potentially Vulnerable to Clickjacking Web Browser XSS Protection Not Enabled    ","categories":"","description":"","excerpt":"DefectDojo attempts to simplify how users interact with the system by …","ref":"/django-DefectDojo/basics/models/","tags":"","title":"Models"},{"body":"Auth0 In the same way as with other identity providers, it’s now possible to leverage Auth0 to authenticate users on DefectDojo.\n  Inside your Auth0 dashboard create a new application (Applications / Create Application / Single Page Web Application).\n  On the new application set the following fields:\n Name: “Defectdojo” Allowed Callback URLs: https://the_hostname_you_have_dojo_deployed:your_server_port/complete/auth0/    Copy the following info from the application:\n Domain Client ID Client Secret    Now, edit the dojo/settings/settings.dist.py file and edit/replace the following information:\nDD_SOCIAL_AUTH_AUTH0_OAUTH2_ENABLED=True DD_SOCIAL_AUTH_AUTH0_KEY=(str, '**YOUR_CLIENT_ID_FROM_STEP_ABOVE**'), DD_SOCIAL_AUTH_AUTH0_SECRET=(str,'**YOUR_CLIENT_SECRET_FROM_STEP_ABOVE**'), DD_SOCIAL_AUTH_AUTH0_DOMAIN=(str, '**YOUR_AUTH0_DOMAIN_FROM_STEP_ABOVE**'),    Restart DefectDojo, and you should now see a Login with Auth0 button on the login page.\n  Google New to DefectDojo, a Google account can now be used for Authentication, Authorization, and a DefectDojo user. Upon login with a Google account, a new user will be created if one does not already exist. The criteria for determining whether a user exists is based on the users username. In the event a new user is created, the username is that of the Google address without the domain. Once created, the user creation process will not happen again as the user is recalled by its username, and logged in. In order to make the magic happen, a Google authentication server needs to be created. Closely follow the steps below to guarantee success.\n Navigate to the following address and either create a new account, or login with an existing one: Google Developers Console Once logged in, find the key shaped button labeled Credentials on the left side of the screen. Click Create Credentials, and choose OAuth Client ID:  Select Web Applications, and provide a descriptive name for the client.  Add the pictured URLs in the Authorized Redirect URLs section. This part is very important. If there are any mistakes here, the authentication client will not authorize the request, and deny access. Once all URLs are added, finish by clicking Create  Now with the authentication client created, the Client ID and Client Secret Key need to be copied over to dojo/settings/settings.dist.py in the project. Click the newly created client and copy the values:\nIn the Environment section at the top of dojo/settings/settings.dist.py, enter the values as shown below:\nIn the Authentication section of dojo/settings/settings.dist.py, set DD_GOOGLE_OAUTH_ENABLED to True to redirect away from this README and actually authorize.\nTo authorize users you will need to set the following:\nSOCIAL_AUTH_GOOGLE_OAUTH2_WHITELISTED_DOMAINS = ['example.com', 'example.org'] or\nSOCIAL_AUTH_GOOGLE_OAUTH2_WHITELISTED_EMAILS = ['\u003cemail@example.com\u003e'] OKTA In a similar fashion to that of Google, using OKTA as a OAuth2 provider carries the same attributes and a similar procedure. Follow along below.\n Navigate to the following address and either create a new account, or login with an existing one: OKTA Account Creation Once logged in, enter the Applications and click Add Application:  Select Web Applications.  Add the pictured URLs in the Login Redirect URLs section. This part is very important. If there are any mistakes here, the authentication client will not authorize the request, and deny access. Check the Implicit box as well.  Once all URLs are added, finish by clicking Done. Return to the Dashboard to find the Org-URL. Note this value as it will be important in the settings file.  Now, with the authentication client created, the Client ID and Client Secret Key need to be copied over to dojo/settings/settings.dist.py in the project. Click the newly created client and copy the values:\nIn the Environment section at the top of dojo/settings/settings.dist.py, enter the values as shown below:\nIn the Authentication section of dojo/settings/settings.dist.py, set DD_OKTA_OAUTH_ENABLED to True to redirect away from this README and actually authorize.\nIf during the login process you get the following error: The ‘redirect_uri’ parameter must be an absolute URI that is whitelisted in the client app settings. and the redirect_uri HTTP GET parameter starts with http:// instead of https:// you need to add SOCIAL_AUTH_REDIRECT_IS_HTTPS = True in the Authentication section of dojo/settings/settings.dist.py.\nAzure Active Directory You can now use your corporate Azure Active Directory to authenticate users to Defect Dojo. Users will be using your corporate Azure AD account (A.K.A. Office 365 identity) to authenticate via OAuth, and all the conditional access rules and benefits from Azure Active Directory will also apply to the Defect Dojo Authentication. Once the user signs in, it will try to match the UPN of the user to an existing e-mail from a user in Defect Dojo, and if no match is found, a new user will be created in Defect Dojo, associated with the unique id/value of the user provided by your Azure AD tenant. Then, you can assign roles to this user, such as ‘staff’ or ‘superuser’\n  Navigate to the following address and follow instructions to create a new app registration\n https://docs.microsoft.com/en-us/azure/active-directory/develop/quickstart-register-app    Once you register an app, take note of the following information:\n Application (client) ID Directory (tenant) ID Under Certificates \u0026 Secrets, create a new Client Secret    Under Authentication \u003e Redirect URIs, add a WEB type of uri where the redirect points to\n http://localhost:8080/complete/azuread-tenant-oauth2/ OR https://the_hostname_you_have_dojo_deployed:your_server_port/complete/azuread-tenant-oauth2/    Now, edit the dojo/dojo/settings/settings.dist.py file and edit/replace the following information:\nDD_SOCIAL_AUTH_AZUREAD_TENANT_OAUTH2_KEY=(str, 'YOUR_APPLICATION_ID_FROM_STEP_ABOVE'), DD_SOCIAL_AUTH_AZUREAD_TENANT_OAUTH2_SECRET=(str, 'YOUR_CLIENT_SECRET_FROM_STEP_ABOVE'), DD_SOCIAL_AUTH_AZUREAD_TENANT_OAUTH2_TENANT_ID=(str, 'YOUR_DIRECTORY_ID_FROM_STEP_ABOVE'), DD_SOCIAL_AUTH_AZUREAD_TENANT_OAUTH2_ENABLED = True    Restart your Dojo, and you should now see a Login with Azure AD button on the login page which should magically work\n  Gitlab In a similar fashion to that of Google and OKTA, using Gitlab as a OAuth2 provider carries the same attributes and a similar procedure. Follow along below.\n  Navigate to your Gitlab settings page and got to the Applications section\n https://gitlab.com/profile/applications OR https://the_hostname_you_have_gitlab_deployed:your_gitlab_port/profile/applications    Choose a name for your application\n  For the Redirect URI, enter the DefectDojo URL with the following format\n https://the_hostname_you_have_dojo_deployed:your_server_port/complete/gitlab/    Now, edit the dojo/dojo/settings/settings.dist.py file and edit/replace the following information:\nDD_SOCIAL_AUTH_GITLAB_KEY=(str, 'YOUR_APPLICATION_ID_FROM_STEP_ABOVE'), DD_SOCIAL_AUTH_GITLAB_SECRET=(str, 'YOUR_SECRET_FROM_STEP_ABOVE'), DD_SOCIAL_AUTH_GITLAB_API_URL=(str, 'https://gitlab.com'), DD_SOCIAL_AUTH_GITLAB_OAUTH2_ENABLED = True  Additionally, if you want to import your Gitlab projects as DefectDojo products, add the following line, still in dojo/dojo/settings/settings.dist.py:\nDD_SOCIAL_AUTH_GITLAB_PROJECT_AUTO_IMPORT = True    Restart DefectDojo, and you should now see a Login with Gitlab button on the login page.\n  SAML 2.0 Warning The SAML integration below is based on https://github.com/fangli/django-saml2-auth which is no longer maintained, see #3890  In a similar direction to OAuth, this SAML addition provides a more secure perogative to SSO. For definitions of terms used and more information, see the plugin plugin homepage\n  Navigate to your SAML IdP and find your metadata\n  Edit the dojo/dojo/settings/settings.dist.py file:\nDD_SAML2_ENABLED=(bool, **True**), # If the metadata can be accessed from a url, try the DD_SAML2_METADATA_AUTO_CONF_URL DD_SAML2_METADATA_AUTO_CONF_URL=(str, '\u003chttps://your_IdP.com/metadata.xml\u003e'), # Otherwise, downlaod a copy of the metadata into an xml file, and # list the path in DD_SAML2_METADATA_LOCAL_FILE_PATH DD_SAML2_METADATA_LOCAL_FILE_PATH=(str, '/path/to/your/metadata.xml'), # Fill in DD_SAML2_ASSERTION_URL and DD_SAML2_ENTITY_ID to # match the specs of you IdP. # Configure the remaining optional fields to your desire.    In the “Authentication” section of the dojo/settings/settings.dist.py, do the following\n Find the “SAML_2_AUTH” dictionary Comment out the metadata collection method that was not used. For example, if METADATA_AUTO_CONF_URL was used, comment the METADATA_LOCAL_FILE_PATH line.    Restart DefectDojo, and you should now see a Login with SAML button on the login page.\n  NOTE: In the case when IDP is configured to use self signed certificate, than CA needs to be specified by define environments variable REQUESTS_CA_BUNDLE that points to the path of public CA certificate.\nUser Permissions When a new user is created via the social-auth, only the default permissions are active. This means that the newly created user does not have access to add, edit, nor delete anything within DefectDojo. To circumvent that, a custom pipeline was added (dojo/pipline.py/modify_permissions) to elevate new users to staff. This can be disabled by setting ‘is_staff’ equal to False. Similarly, for an admin account, simply add the following to the modify_permissions pipeline:\nis_superuser = True Exception for Gitlab OAuth2: with DD_SOCIAL_AUTH_GITLAB_PROJECT_AUTO_IMPORT set to True in dojo/settings/settings.dist.py, where a new user is created via the Gitlab social-auth, he has one permission: add_engagement. It allows him to create further engagements on his products via the API.\nOther Providers In an effort to accommodate as much generality as possible, it was decided to implement OAuth2 with the social-auth ecosystem as it has a library of compatible providers with documentation of implementation. Conveniently, each provider has an identical procedure of managing the authenticated responses and authorizing access within a given application. The only difficulty is creating a new authentication client with a given OAuth2 provider.\n","categories":"","description":"","excerpt":"Auth0 In the same way as with other identity providers, it’s now …","ref":"/django-DefectDojo/integrations/social-authentication/","tags":"","title":"Authentication via OAuth2"},{"body":"Below are the main sections within DefectDojo. Each is designed to allow for ease of use and simple organization of Products and their Tests. The models page will help you understand the terminology we use below, so we recommend taking a look at that first.\nProducts The following attributes describe a Product:\n Name A short name for the product, used for easy identification. This field can hold up to 300 characters. Description Used to fully describe the product. This field can hold up to 2000 characters. Product Manager Provides the ability to store who manages the product lifecycle. Useful for contacting team members. This field can hold up to 200 characters. Technical Contact Provides the ability to store who should be contacted in case of technical questions and/or difficulties. This field can hold up to 200 characters. Manager Provides the ability to store who manages the technical resources for the product. This field can hold up to 200 characters. Date Created Stores when the Product was first added to DefectDojo. Date Updated Stores when the Product was updated. Business Criticality Criticality of the product. Platform Type of product: web, API, mobile etc. Lifecycle Stage of product development Product Type Used to group products together. Authorized Users List of users who are allowed to view and interact with the product.  Products are listed on the /product page and can be filtered by their attributes as well as sorted by their name and product type.\nVisual representation of a product:\nProduct with metrics:\nEngagements The following attributes describe an Engagement:\n Name Helps distinguish one Engagement from another on the same product. This field can hold up to 300 characters. Target Start Date The projected start date for this engagement. Target End Date The projected end date for this engagement. Lead The DefectDojo user who is considered the lead for this group of tests. Product The Product being tested as part of this group of tests. Active Denotes if the Engagement is currently active or not. Test Strategy The URL of the testing strategy defined for this Engagement. Threat Model The document generated by a threat modeling session discussing the risks associated with this product at this moment in time. Hash Code A hash over a configurable set of fields that is used for findings deduplication. Payload Payload used to attack the service / application and trigger the bug / problem. Status Describes the current state of the Engagement. Values include In Progress, On Hold and Completed.  Engagements are listed in the /engagement page and can be filtered by their attributes as well as sorted by the product or product type.\nVisual representation of an engagement:\nEndpoints Endpoints represent testable systems defined by IP address or Fully Qualified Domain Name.\nThe following attributes describe an Endpoint:\n Protocol The communication protocol such as 'http', 'https', 'ftp', etc. Host The host name or IP address, you can also include the port number. For example '127.0.0.1', '127.0.0.1:8080', 'localhost', 'yourdomain.com'. Path The location of the resource, it should start with a '/'. For example \"/endpoint/420/edit\" Query The query string, the question mark should be omitted. \"For example 'group=4\u0026team=8' Fragment The fragment identifier which follows the hash mark. The hash mark should be omitted. For example 'section-13', 'paragraph-2'. Product The Product that this endpoint should be associated with.  Endpoints are listed in the /endpoints page and can be filtered by their attributes as well as sorted by the product or host.\nVisual representation of an endpoint:\nVisual representation of an endpoint with metrics displayed:\nFindings Findings represent a flaw within the product being tested. The following attributes help define a Finding:\n Title A short description of the flaw (Up to 511 characters). Description Longer more descriptive information about the flaw. Date The date the flaw was discovered. CVE The Common Vulnerabilities and Exposures (CVE) associated with this flaw. CVSSV3 Common Vulnerability Scoring System version 3 (CVSSv3) score associated with this flaw. CWE The CWE number associated with this flaw. URL External reference that provides more information about this flaw. Severity The severity level of this flaw (Critical, High, Medium, Low, Informational) Numerical Severity The numerical representation of the severity (S0, S1, S2, S3, S4) Mitigation Text describing how to best fix the flaw. Impact Text describing the impact this flaw has on systems, products, enterprise, etc. Steps to Reproduce Text describing the steps that must be followed in order to reproduce the flaw / bug. Severity Justification Text describing why a certain severity was associated with this flaw. Endpoints The hosts within the product that are susceptible to this flaw. Endpoint Status The status of the endpoint associated with this flaw (Vulnerable, Mitigated, ...). References The external documentation available for this flaw. Thread ID Thread ID Hash Code A hash over a configurable set of fields that is used for findings deduplication. Test The test that is associated with this flaw. Is Template Denotes if this finding is a template and can be reused. Active Denotes if this flaw is active or not. Verified Denotes if this flaw has been manually verified by the tester. False Positive Denotes if this flaw has been deemed a false positive by the tester. Duplicate Denotes if this flaw is a duplicate of other flaws reported. Duplicate Finding Link to the original finding if this finding is a duplicate. Out Of Scope Denotes if this flaw falls outside the scope of the test and/or engagement. Under Review Denotes is this flaw is currently being reviewed. Mitigated Denotes if this flaw has been fixed, by storing the date it was fixed. Is Mitigated Denotes if this flaw has been fixed. Mitigated By Documents who has deemed this flaw as fixed. Reporter Documents who reported the flaw. Reviewers Document who reviewed the flaw. Last Reviewed Provides the date the flaw was last \"touched\" by a tester. Last Reviewed By Provides the person who last reviewed the flaw. Component Name Name of the affected component (library name, part of a system, ...). Component Version Version of the affected component. Found By The name of the scanner that identified the flaw. SonarQube Issue The SonarQube issue associated with this finding. Unique ID from tool Vulnerability technical id from the source tool. Allows to track unique vulnerabilities. Defect Review Requested By Document who requested a defect review for this flaw. Under Defect Review Denotes if this finding is under defect review. Review Requested By Document who requested a review for this finding. Static Finding Flaw has been detected from a Static Application Security Testing tool (SAST). Dynamic Finding Flaw has been detected from a Dynamic Application Security Testing tool (DAST). Jira Creation The date a Jira issue was created from this finding. Jira Change The date the linked Jira issue was last modified. SLA Days Remaining The number of day remaining to stay within the SLA. Finding Meta Custom metadata (K/V) that can be set on top of findings. Tags Add custom tags on top of findings (helpful for searching). Created The date the finding was created inside DefectDojo. Param Parameter used to trigger the issue (DAST). Payload Payload used to attack the service / application and trigger the bug / problem. Age The number of days since the finding was created. Scanner confidence Confidence level of vulnerability which is supplied by the scanner. Number of Occurrences Number of occurrences in the source tool when several vulnerabilities were found and aggregated by the scanner. Source File Name of the source code file in which the flaw is located. Source File Path Filepath of the source code file in which the flaw is located. Notes Stores information pertinent to the flaw or the mitigation. Initially there isn't a way to categorize notes added for Findings. Admin can introduce a new attribute to notes as 'note-type' which can categorize notes. To enable note-types go to System Settings, select Note Types and add new note-types to Dojo.  Note-type  A note-type has 5 attributes.\n Name Description is_active - This has to be true to assign the note-type to a note. is_single - If true, only one note of that note-type can exist for a Finding. is_mandatory - If true, a Finding has to have at least one note from the note-type in order to close it.    If note-types are enabled, User has to first select the note-type from the \"Note Type\" drop down and then add the contents of the note.\n Images  Image(s) / Screenshot(s) related to the flaw.\n  SAST specific For SAST, when source (start of the attack vector) and sink (end of the attack vector) information are available.\n Line Source line number of the attack vector. Line Number Deprecated will be removed, use line. File Path Identified file(s) containing the flaw. SAST Source Object Source object (variable, function...) of the attack vector. SAST Sink Object Sink object (variable, function...) of the attack vector. SAST Source line Source line number of the attack vector, SAST Source File Path Source file path of the attack vector.  Images  Images Finding images can now be uploaded to help with documentation and proof of vulnerability.  If you are upgrading from an older version of DefectDojo, you will have to complete the following and make sure MEDIA_ROOT and MEDIA_URL are properly configured:\nAdd imagekit to INSTALLED_APPS:\nINSTALLED_APPS = ( 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.sites', 'django.contrib.messages', 'django.contrib.staticfiles', 'polymorphic', # provides admin templates 'overextends', 'django.contrib.admin', 'django.contrib.humanize', 'gunicorn', 'tastypie', 'djangobower', 'auditlog', 'dojo', 'tastypie_swagger', 'watson', 'tagging', 'custom_field', 'imagekit', ) Add r\\'\\^media/\\' to LOGIN_EXEMPT_URLS:\nLOGIN_EXEMPT_URLS = ( r'^static/', r'^ajax/v1/', r'^reports/cover$', r'^finding/image/(?P\u003ctoken\u003e[^/]+)$' ) Then run the following commands (make sure your virtual environment is activated):\npip install django-imagekit pip install pillow --upgrade ./manage.py makemigrations dojo ./manage.py makemigrations ./manage.py migrate New installations will already have finding images configured.\nFindings are listed on the /finding/open, /finding/closed, /finding/accepted and /finding/all pages. They can be filtered by their attributes as well as sorted by their Name, Date, Reviewed Date, Severity and Product.\nVisual representation of a Finding:\nDeduplication / Similar findings  Automatically Flag Duplicate Findings 'De-duplication' is a feature that when enabled will compare findings to automatically identify duplicates. To enable de-duplication go to System Settings and check Deduplicate findings. Dojo deduplicates findings by comparing endpoints, CWE fields, and titles. If two findings share a URL and have the same CWE or title, Dojo marks the less recent finding as a duplicate. When deduplication is enabled, a list of deduplicated findings is added to the engagement view. The following image illustrates the option deduplication on engagement and deduplication on product level:   Similar Findings Visualization:\n Similar Findings While viewing a finding, similar findings within the same product are listed along with buttons to mark one finding a duplicate of the other. Clicking the \"Use as original\" button on a similar finding will mark that finding as the original while marking the viewed finding as a duplicate. Clicking the \"Mark as duplicate\" button on a similar finding will mark that finding as a duplicate of the viewed finding. If a similar finding is already marked as a duplicate, then a \"Reset duplicate status\" button is shown instead which will remove the duplicate status on that finding along with marking it active again.  Metrics DefectDojo provides a number of metrics visualization in order to help with reporting, awareness and to be able to quickly communicate a products/product type's security stance.\nThe following metric views are provided:\n Product Type Metrics This view provides graphs displaying Open Bug Count by Month, Accepted Bug Count by Month, Open Bug Count by Week, Accepted Bug Count by Week as well as tabular data on Top 10 Products by bug severity, Detail Breakdown of all reported findings, Opened Findings, Accepted Findings, Closed Findings, Trending Open Bug Count, Trending Accepted Bug Count, and Age of Issues.  Product Type Counts This view provides tabular data of Total Current Security Bug Count, Total Security Bugs Opened In Period, Total Security Bugs Closed In Period, Trending Total Bug Count By Month, Top 10 By Bug Severity, and Open Findings. This view works great for communication with stakeholders as it is a snapshot in time of the product.  Simple Metrics Provides tabular data for all Product Types. The data displayed in this view is the total number of S0, S1, S2, S3, S4, Opened This Month, and Closed This Month.  Engineer Metrics Provides graphs displaying information about a tester's activity.  Metrics Dashboard Provides a full screen, auto scroll view with many metrics in graph format. This view is great for large displays or \"Dashboards.\"   Users DefectDojo users inherit from django.contrib.auth.models.User.\nA username, first name, last name, and email address can be associated with each. Additionally the following describe the type of use they are:\n Active Designates whether this user should be treated as active. Unselect this instead of deleting accounts. Staff status Designates whether the user can log into this site. Superuser status Designates that this user has all permissions without explicitly assigning them.  Calendar The calendar view provides a look at all the engagements occurring during the month displayed. Each entry is a direct link to the Engagement view page.\nNotifications DefectDojo can inform you of different events in a variety of ways. You can be notified about things like an upcoming engagement, when someone mentions you in a comment, a scheduled report has finished generating, and more.\nThe following notification methods currently exist: - Email - Slack - Microsoft Teams - Alerts within DefectDojo\nYou can set these notifications on a global scope (if you have administrator rights) or on a personal scope. For instance, an administrator might want notifications of all upcoming engagements sent to a certain Slack channel, whereas an individual user wants email notifications to be sent to the user's specified email address when a report has finished generating.\nMicrosoft Teams does not provide an easy way to send messages to a personal channel. Therefore, DefectDojo can only send system scope notifications to Microsoft Teams.\nIn order to identify and notify you about things like upcoming engagements, DefectDojo runs scheduled tasks for this purpose. These tasks are scheduled and run using Celery beat, so this needs to run for those notifications to work. Instructions on how to run Celery beat are available in the Reports section.\nBenchmarks DefectDojo utilizes the OWASP ASVS Benchmarks to benchmark a product to ensure the product meets your application technical security controls. Benchmarks can be defined per the organizations policy for secure development and multiple benchmarks can be applied to a product.\nBenchmarks are available from the Product view. To view the configured benchmarks select the dropdown menu from the right hand drop down menu. You will find the selection near the bottom of the menu entitled: 'OWASP ASVS v.3.1'.\nIn the Benchmarks view for each product, the default level is ASVS Level\n On the top right hand side the drop down can be changed to the desired ASVS level (Level 1, Level 2 or Level 3). The publish checkbox will display the ASVS score on the product page and in the future this will be applied to reporting.  On the left hand side the ASVS score is displayed with the desired score, the % of benchmarks passed to achieve the score and the total enabled benchmarks for that AVSV level.\nAdditional benchmarks can be added/updated in the Django admin site. In a future release this will be brought out to the UI.\nReports Reports can be generated for:\n Product types Products Engagements Tests List of Findings Endpoints Custom reports  Filtering is available on all report generation views to aid in focusing the report for the appropriate need.\nCustom reports, generated with the Report Builder, allow you to select specific components to be added to the report. These include:\n Cover Page Table of Contents WYSIWYG Content Findings Vulnerable Endpoints Page Breaks  DefectDojo’s reports can be generated in HTML and AsciiDoc.\nIssue Consolidation DefectDojo allows users to automatically consolidate issues from multiple scanners to remove duplicates.\nTo enable this feature, hover over the configuration tab on the left menu and click on system settings. In system settings, click 'Deduplicate findings'. Click 'Submit' at the bottom of the page.\nWhen deduplication is enabled, Dojo will compare CWE, title, and endpoint details for all findings in a given product. If an issue is added with either the CWE or title being the same while the endpoint is also the same, Dojo marks the old issue as a duplicate.\nFalse Positive Removal DefectDojo allows users to tune out false positives by enabling False Positive History. This will track what engineers have labeled as false positive for a specific product and for a specific scanner. While enabled, when a tool reports the same issue that has been flagged as a false positive previously, it will automatically mark the finding as a false positive, helping to tune overly verbose security tools.\nDeduplication Deduplication is a process that allows DefectDojo to find out that a finding has already been imported.\nUpon saving a finding, defectDojo will look at the other findings in the product or the engagement (depending on the configuration) to find duplicates\nWhen a duplicate is found:\n The newly imported finding takes status: inactive, duplicate An \"Original\" link is displayed after the finding status, leading to the original finding  There are two ways to use the deduplication:\n Deduplicate vulnerabilities in the same build/release. The vulnerabilities may be found by the same scanner (same scanner deduplication) or by different scanners (cross-scanner deduplication). this helps analysis and assessment of the technical debt, especially if using many different scanners; although detecting duplicates across scanners is not trivial as it requires a certain standardization. Track unique vulnerabilities across builds/releases so that defectDojo knows when it finds a vulnerability whether it has seen it before.  this allows you keep information attached to a given finding in a unique place: all further duplicate findings will point to the original one.\n  Deduplication Configuration Global configuration The deduplication can be activated in \"System Settings\" by ticking \"Deduplicate findings\".\nAn option to delete duplicates can be found in the same menu, and the maximum number of duplicates to keep for the same finding can be configured.\nEngagement configuration When creating an engagement or later by editing the engagement, the \"Deduplication within engagement only\" checkbox can be ticked.\n If activated: Findings are only deduplicated within the same engagement. Findings present in different engagements cannot be duplicates Else: Findings are deduplicated across the whole product  Note that deduplication can never occur across different products.\nDeduplication algorithms The behavior of the deduplication can be configured for each parser in settings.dist.py (or settings.py after install) by configuring the DEDUPLICATION_ALGORITHM_PER_PARSER variable.\nThe available algorithms are:\n DEDUPE_ALGO_UNIQUE_ID_FROM_TOOL The deduplication occurs based on finding.unique_id_from_tool which is a unique technical id existing in the source tool. Few scanners populate this field currently. If you want to use this algorithm, you may need to update the scanner code beforehand.  Advantages:  If your source tool has a reliable means of tracking a unique vulnerability across scans, this configuration will allow defectDojo to use this ability.   Drawbacks:  Using this algorithm will not allow cross-scanner deduplication as other tools will have a different technical id. When the tool evolves, it may change the way the unique id is generated. In that case you won't be able to recognise that findings found in previous scans are actually the same as the new findings.     DEDUPE_ALGO_HASH_CODE The deduplication occurs based on finding.hash_code. The hash_code itself is configurable for each scanner in parameter HASHCODE_FIELDS_PER_SCANNER. DEDUPE_ALGO_UNIQUE_ID_FROM_TOOL_OR_HASH_CODE A finding is a duplicate with another if they have the same unique_id_from_tool OR the same hash_code.  Allows to use both  a technical deduplication (based on unique_id_from_tool) for a reliable same-parser deduplication and a functional one (based on hash_code configured on CWE+severity+file_path for example) for cross-parser deduplication     DEDUPE_ALGO_LEGACY This is algorithm that was in place before the configuration per parser was made possible, and also the default one for backward compatibility reasons.  Legacy algorithm basically deduplicates based on:  For static scanner: ['title', 'cwe', 'line', 'file_path', 'description'] For dynamic scanner: ['title', 'cwe', 'line', 'file_path', 'description', 'endpoints']    Note that there are some subtleties that may give unexpected results. Switch dojo.specific-loggers.deduplication to debug in settings.py to get more info in case of trouble.\n  Hash_code computation configuration The hash_code computation can be configured for each parser using the parameter HASHCODE_FIELDS_PER_SCANNER in settings.dist.py.\nThe parameter HASHCODE_ALLOWED_FIELDS list the fields from finding table that were tested and are known to be working when used as a hash_code. Don't hesitate to enrich this list when required (the code is generic and allows adding new fields by configuration only)\nNote that endpoints isn't a field from finding table but rather a meta value that will trigger a computation based on all the endpoints.\nWhen populating HASHCODE_FIELDS_PER_SCANNER, please respect the order of declaration of the fields: use the same order as in HASHCODE_ALLOWED_FIELDS: that will allow cross-scanner deduplication to function because the hash_code is computed as a sha-256 of concatenated values of the configured fields.\nTips:\n  It's advised to use fields that are standardized for a reliable deduplication, especially if aiming at cross-scanner deduplication. For example title and description tend to change when the tools evolve and don't allow cross-scanner deduplication\n Good candidates are  cwe or cve Adding the severity will make sure the deduplication won't be to aggressive (there are several families of XSS and sql injection for example, with various severities but the same cwe). Adding the file_path or endpoints is advised too.      The parameter HASHCODE_ALLOWS_NULL_CWE will allow switching to legacy algorithm when a null cwe is found for a given finding: this is to avoid getting many duplicates when the tool fails to give a cwe while we are expecting it.\n  Hashcode generation / regeneration When you change the hashcode configuration, it is needed to regenerated the hashcodes for all findings, or at least those findings found by scanners for which the configuration was updated.\nThis is sometimes also needed after an upgrade to a new Defect Dojo version, for example when we made changes to the hashcode configuration or calculation logic. We will mention this in the upgrade notes.\nTo regenerate the hashcodes, use the dedupe management command:\ndocker-compose exec uwsgi ./manage.py dedupe --hash_code_only This will only regenerated the hashcodes, but will not run any deduplication logic on existing findings. If you want to run deduplication again on existing findings to make sure any duplicates found by the new hashcode config are marked as such, run\ndocker-compose exec uwsgi ./manage.py dedupe The deduplication part of this command will run the deduplication for each finding in a celery task. If you want to run the deduplication in the foreground process, use:\ndocker-compose exec uwsgi ./manage.py dedupe --dedupe-sync Please note the deduplication process is resource intensive and can take a long time to complete (estimated ~7500 findings per minute when run in the foreground)\nDebugging deduplication There is a specific logger that can be activated in order to have details about the deduplication process : switch dojo.specific-loggers.deduplication to debug in settings.dist.py.\nDeduplication - APIv2 parameters  skip_duplicates: if true, duplicates are not inserted at all close_old_findings : if true, findings that are not duplicates and that were in the previous scan of the same type (example ZAP) for the same product (or engagement in case of \"Deduplication on engagement\") and that are not present in the new scan are closed (Inactive, Verified, Mitigated)  Service Level Agreement (SLA) DefectDojo allows you to maintain your security SLA and automatically remind teams whenever a SLA is about to get breached, or breaches.\nSimply indicate in the System Settings for each severity, how many days teams have to remediate a finding.\nSLA notification configuration There are 5 variables in the settings.py file that you can configure, to act on the global behavior. By default, any findings across the instance that are in Active, Verified state will be considered for notifications.\nSLA_NOTIFY_ACTIVE = False SLA_NOTIFY_ACTIVE_VERIFIED_ONLY = True SLA_NOTIFY_WITH_JIRA_ONLY = False SLA_NOTIFY_PRE_BREACH = 3 SLA_NOTIFY_POST_BREACH = 7 Setting both SLA_NOTIFY_ACTIVE and SLA_NOTIFY_ACTIVE_VERIFIED_ONLY to False will effectively disable SLA notifications.\nYou can choose to only consider findings that have a JIRA issue linked to them. If so, please set SLA_NOTIFY_WITH_JIRA_ONLY to True.\nThe SLA_NOTIFY_PRE_BREACH is expressed in days. Whenever a finding's \"SLA countdown\" (time to remediate) drops to this number, a notification would be sent everyday, as scheduled by the crontab in settings.py, until the day it breaches.\nThe SLA_NOTIFY_POST_BREACH lets you define in days how long you want to be kept notified about findings that have breached the SLA. Passed that number, notifications will cease.\nWarning Be mindful of performance if you choose to have SLA notifications on non-verified findings, especially if you import a lot of findings through CI in 'active' state.  What notification channels for SLA notifications? The same as usual. You will notice that an extra SLA breach option is now present on the Notification page and also in the Product view.\nSLA notification with JIRA You can choose to also send SLA notification as JIRA comments, if your product is configured with JIRA. You can enable it at the JIRA configuration level or at the Product level.\nThe Product level JIRA notification configuration takes precendence over the global JIRA notification configuration.\nWhen is the SLA notification job run? The default setup will trigger the SLA notification code at 7:30am on a daily basis, as defined in the settings.py file. You can of course modify this schedule to your context.\n'compute-sla-age-and-notify': { 'task': 'dojo.tasks.async_sla_compute_and_notify', 'schedule': crontab(hour=7, minute=30), } Information The celery containers are the ones concerned with this configuration. If you suspect things are not working as expected, make sure they have the latest version of your settings.py file.  You can of course change this default by modifying that stanza.\nLaunching from the CLI You can also invoke the SLA notification function from the CLI. For example, if run from docker-compose:\n$ docker-compose exec uwsgi /bin/bash -c 'python manage.py sla_notifications' ","categories":"","description":"","excerpt":"Below are the main sections within DefectDojo. Each is designed to …","ref":"/django-DefectDojo/basics/features/","tags":"","title":"Features"},{"body":"","categories":"","description":"","excerpt":"","ref":"/django-DefectDojo/running/","tags":"","title":"Running DefectDojo"},{"body":"","categories":"","description":"","excerpt":"","ref":"/django-DefectDojo/contributing/","tags":"","title":"Contributing"},{"body":"DefectDojo's JIRA integration is bidirectional. You may push findings to JIRA and share comments. If an issue is closed in JIRA it will automatically be closed in Dojo.\nNOTE: These steps will configure the necessary webhook in JIRA and add JIRA integration into DefectDojo. This isn't sufficient by itself, you will need to configure products and findings to push to JIRA. On a product's settings page you will need to define a:\n Project Key (and this project must exist in JIRA) JIRA Configuration (select the JIRA configuration that you create in the steps below) Component (can be left blank)  Then elect (via tickbox) whether you want to 'Push all issues', 'Enable engagement epic mapping' and/or 'Push notes'. Then click on 'Submit'.\nIf creating a Finding, ensure to tick 'Push to jira' if desired.\nEnabling the Webhook  Visit https://\u003cYOUR JIRA URL\u003e/plugins/servlet/webhooks Click 'Create a Webhook' For the field labeled 'URL' enter: https://\u003cYOUR DOJO DOMAIN\u003e/webhook/ Under 'Comments' enable 'Created'. Under Issue enable 'Updated'.  Configurations in Dojo  Navigate to the System Settings from the menu on the left side or by directly visiting \u003cyour url\u003e/system_settings. Enable 'Enable JIRA integration' and click submit.  Adding JIRA to Dojo  Click 'JIRA' from the left hand menu. Select 'Add Configuration' from the drop-down. If you use Jira Cloud, you will need to generate an API token for Jira to use as the password To obtain the 'open status key' and 'closed status key' visit https://\u003cYOUR JIRA URL\u003e/rest/api/latest/issue/\u003cANY VALID ISSUE KEY\u003e/transitions?expand=transitions.fields The 'id' for 'Todo' should be filled in as the 'open status key' The 'id' for 'Done' should be filled in as the 'closed status key'  To obtain 'epic name id': If you have admin access to JIRA:\n visit: https://\u003cYOUR JIRA URL\u003e/secure/admin/ViewCustomFields.jspa Click on the cog next to 'Epic Name' and select view. The numeric value for 'epic name id' will be displayed in the URL Note: dojojira uses the same celery functionality as reports. Make sure the celery runner is setup correctly as described: https://defectdojo.github.io/django-DefectDojo/basics/features/#reports  Or\n login to JIRA visit https://yourjiraurl/rest/api/2/field and use control+F or grep to search for 'Epic Name' it should look something like this:  { “id”:“customfield_122”, “key”:“customfield_122”, “name”:“Epic Name”, “custom”:true, “orderable”:true, “navigable”:true, “searchable”:true, “clauseNames”:“cf[122]”, “Epic Name”], “schema”:{“type”:“string”,“custom”:“com.pyxis.greenhopper.jira:gh-epic-label”,“customId”:122} }\nIn the above example 122 is the number needed\nCustomize JIRA issue description By default Defect Dojo uses the dojo/templates/issue-trackers/jira_full/jira-description.tpl template to render the description of the ‘to be’ created JIRA issue. This file can be modified to your needs, rebuild all containers afterwards. There’s also a more limited template available, which can be chosen when configuring a JIRA Instance or JIRA Project for a Product or Engagement:\nAny folder added to dojo/templates/issue-trackers/ will be added to the dropdown (after rebuilding/restarting the containers).\nEngagement Epic Mapping If creating an Engagement, ensure to tick ‘Enable engagement epic mapping’ if desired. This can also be done after engagement creation on the edit engagement page. This will create an ‘Epic’ type issue within Jira. All findings in the engagement pushed to Jira will have a link to this Epic issue. If Epic Mapping was enabled after associated findings have already been pushed to Jira, simply pushing them again will link the Jira issue to the Epic issue.\nPushing findings Findings can be pushed to Jira in a number of ways:\n When importing scanner reports, select ‘Push to JIRA’ to push every single finding in the report to Jira When creating a new finding, select ‘Push to JIRA’ and submit. This will create the finding in DefectDojo and Jira simultaneously If a finding already exist, visit the edit finding page and find the ‘Push to JIRA’ tick box at the bottom When viewing a list of findings, select each relevant tick boxes to the left of the finding, and click the ‘Bulk Edit’ button at the top. find ‘Push to JIRA’ at the bottom of the menu  Status Sync DefectDojo will try to keep the status in sync with the status in JIRA using the Close and Reopen transition IDs configured for each JIRA instance. This will only work if your workflow in JIRA allows the Close transition to be performed from every status a JIRA issue can be in.\nKnown Issues The Risk Acceptance feature in DefectDojo will (for that reason) not (yet) try to sync statuses. A comment will be pushed to JIRA if a finding is risk accepted or unaccepted. Contributions are welcome to enhance the integration.\nStatus reconciliation Sometimes JIRA is down, or Defect Dojo is down, or there was bug in a webhook. In this case JIRA can become out of sync with Defect Dojo. If this is the case for lots of issues, manual reconciliation might not be feasible. For this scenario there is the management command ‘jira_status_reconciliation’.\nusage: manage.py jira_status_reconciliation [-h] [--mode MODE] [--product PRODUCT] [--engagement ENGAGEMENT] [--dryrun] [--version] [-v {0,1,2,3}] Reconcile finding status with JIRA issue status, stdout will contain semicolon seperated CSV results. Risk Accepted findings are skipped. Findings created before 1.14.0 are skipped. optional arguments: -h, --help show this help message and exit --mode MODE - reconcile: (default)reconcile any differences in status between Defect Dojo and JIRA, will look at the latest status change timestamp in both systems to determine which one is the correct status - push_status_to_jira: update JIRA status for all JIRA issues connected to a Defect Dojo finding (will not push summary/description, only status) - import_status_from_jira: update Defect Dojo finding status from JIRA --product PRODUCT Only process findings in this product (name) --engagement ENGAGEMENT Only process findings in this product (name) --dryrun Only print actions to be performed, but make no modifications. -v {0,1,2,3}, --verbosity {0,1,2,3} Verbosity level; 0=minimal output, 1=normal output, 2=verbose output, 3=very verbose output This can be executed from the uwsgi docker container using:\n$ docker-compose exec uwsgi /bin/bash -c 'python manage.py jira_status_reconciliation' DEBUG output can be obtains via -v 3, but only after increasing the logging to DEBUG level in your settings.dist.py or local_settings.py file\n$ docker-compose exec uwsgi /bin/bash -c 'python manage.py jira_status_reconciliation -v 3' At the end of the command a semicolon seperated CSV summary will be printed. This can be captured by redirecting stdout to a file:\n$ docker-compose exec uwsgi /bin/bash -c 'python manage.py jira_status_reconciliation \u003e jira_reconciliation.csv' Troubleshooting JIRA integration JIRA actions are typically performed in the celery background process. Errors are logged as alerts/notifications to be seen on the top right of the DefectDojo UI and in stdout of the celery workers.\n","categories":"","description":"","excerpt":"DefectDojo's JIRA integration is bidirectional. You may push findings …","ref":"/django-DefectDojo/integrations/jira/","tags":"","title":"JIRA Integration"},{"body":" Warning The permissions described on this page only become active if you set the FEATURE_AUTHORIZATION_V2 feature flag to True. This feature is currently in beta, you should not use it in production environments.  Users have different functionality available to them, depending on their system-wide permissions and on the role they have as a member of a particular Product or Product Type.\nSystem-wide permissions  Administrators (aka super users) have no limitations in the system. They can change all settings, manage users and have read and write access to all data. Staff users can add Product Types, and have access to data according to their role in a Product or Product Type. There is the parameter AUTHORIZATION_STAFF_OVERRIDE in the settings to give staff users full access to all Products and Product Types. Guest users have limited functionality available. They cannot add Product Types but have access to data according to their role in a Product or Product Type  Product and Product Type permissions Users can be assigned as members to Products and Product Types, giving them one out of five predefined roles. The roles define what kind of access a user has to functions for interacting with data of that Product or Product Type:\nProduct / Product Type roles:\n    Reader Writer Maintainer Owner API Importer     Add Product Type 1)        View Product Type x x x x    Remove yourself as a member x x x x    Manage Product Type members   x x    Edit Product Type   x x    Add Product   x x    Add Product Type member as Owner    x    Delete Product Type    x            View Product x x x x    Remove yourself as a member x x x x    Manage Product members   x x    Edit Product   x x    Add Product member as Owner    x    Delete Product    x            View Engagement x x x x    Add Engagement  x x x    Edit Engagement  x x x    Risk Acceptance  x x x    Delete Engagement   x x            View Test x x x x    Add Test  x x x    Edit Test  x x x    Delete Test   x x            View Finding x x x x    Add Finding  x x x    Edit Finding  x x x    (Re-)Import Scan Result  x x x x   Delete Finding   x x            View Finding Group x x x x    Add Finding Group  x x x    Edit Finding Group  x x x    Delete Finding Group  x x x            View Endpoint x x x x    Add Endpoint  x x x    Edit Endpoint  x x x    Delete Endpoint   x x            Edit Benchmark  x x x    Delete Benchmark   x x            View Components x x x x            View Note History x x x x    Add Note  x x x    Edit Note  x x x    Delete Note  (x) 2) x x     1) Every staff user and administrator can add Product Types. Guest users are not allowed to add Product Types.\n2) Every user is allowed to delete his own notes.\nThe role of a user within a Product Type is inherited by all Products of that Product Type, unless the user is explicitly defined as a member of a Product with a different role. If a user is a member of a Product, his role in the Product must be at least the same level or higher as his role for the respective Product Type.\nA Product Type needs to have at least one owner. The last owner cannot be removed.\n","categories":"","description":"","excerpt":" Warning The permissions described on this page only become active if …","ref":"/django-DefectDojo/basics/permissions/","tags":"","title":"Permissions"},{"body":"Example 1 - Bill the security engineer Bill wants a place to keep track of what he's worked on, so that he can show his boss exactly what issues he reports, and statistics about how long it takes to close them.\nWhen he is asked to audit an application, Bill registers a new Product in DefectDojo, and creates a new Engagement. Here he sets some basic information, like how long he expects the Engagement will take, who will be leading the testing (himself), what Product he will be working on, and what tests he will be doing.\nNext, he can add a Test to the Engagement, or upload a Nessus scan and start picking out the real vulnerabilities from the false positives (Nessus scan Findings are imported as inactive by default).\nWithin the Test section, Bill can add Findings for any issues that he has uncovered during his audit. He can assign a severity to the Findings, describe replication steps, mitigation strategies, and impact on the system. This will come in handy when he wants to generate a report to send to the development team responsible for this Product, or his manager.\nOnce Bill has completed his Engagement, he can close the Engagement on the main Engagement page. He can then view the results of his Tests, and generate a report to send to the development team.\nIf Bill hears back from the development team that they won't be able to fix the issue for a while, he can make a note of this on the Engagement page. Bill will also receive Alerts for any bugs that persist longer than they are supposed to based on their severity.\nExample 2 - John the QE manager John wants to keep tabs on what his team members are up to, and find issues that are taking a long time to get fixed. He creates his own DefectDojo account with superuser privileges so that he can view other team members' metrics.\nTo get a better idea of what his team members are currently working on, he can start by checking the Calendar. This will show him any active Engagements that his team is involved in, based on the dates assigned to those Engagements.\nHe can view metrics for a Product Type, such as \"Third Party Apps\" to track his team's activity and follow up with Product teams who have long-lived bugs. He can also look at all the Findings for which there is a Risk Acceptance associated, and ensure that the proper documentation or timeline has been provided for the Findings in question.\nIf he wants to check on a particular team member's progress, he can look at the Engineer Metrics dashboard under \"Additional Metrics\" for that user.\n","categories":"","description":"","excerpt":"Example 1 - Bill the security engineer Bill wants a place to keep …","ref":"/django-DefectDojo/basics/workflows/","tags":"","title":"Workflows"},{"body":"Findings can have a filepath and a line number as the location of the vulnerability. This is typically set when scanning an application with a Static Application Security Test (SAST) tool. If the repository of the source code is specified in the Engagement, DefectDojo will present the filepath as a link and the user can navigate directly to the location of the vulnerability.\nSetting the repository in the Engagement While editing the Engagement, users can set the URL of the repo. It needs to be the URL including the branch, e.g. https://github.com/DefectDojo/django-DefectDojo/tree/dev (GitHub) or https://gitlab.com/gitlab-org/gitlab/-/tree/master (GitLab).\nLink in Finding When viewing a finding, the location will be presented as a link, if the repository of the source code has been set in the Engagement:\nClicking on this link will open a new tab in the browser, with the source file of the vulnerability at the corresponding line number:\n","categories":"","description":"","excerpt":"Findings can have a filepath and a line number as the location of the …","ref":"/django-DefectDojo/integrations/source-code-repositories/","tags":"","title":"Source code repositories"},{"body":"With the Google Sheets sync feature, DefectDojo allow the users to export all the finding details of each test into a separate Google Spreadsheet. Users can review and edit finding details via Google Spreadsheets. Also, they can add new notes to findings and edit existing notes using the Google Spreadsheet. After reviewing and updating the finding details in the Google Spreadsheet, the user can import (sync) all the changes done via the Google Spreadsheet into DefectDojo database.\nConfiguration Creating a project and a Service Account\n Go to the Service Accounts page. Create a new project for DefectDojo and select it. Click +CREATE SERVICE ACCOUNT, enter a name and description for the service account. You can use the default service account ID, or choose a different, unique one. When done click Create. The Service account permissions (optional) section that follows is not required. Click Continue. On the Grant users access to this service account screen, scroll down to the Create key section. Click +Create key. In the side panel that appears, select the format for your key as JSON Click Create. Your new public/private key pair is generated and downloaded to your machine.  Enabling the required APIs\n Go to the Google API Console. From the projects list, select the project created for DefectDojo. If the APIs \u0026 services page isn't already open, open the console left side menu and select APIs \u0026 services, and then select Library. Google Sheets API and Google Drive API should be enabled. Click the API you want to enable. If you need help finding the API, use the search field. Click ENABLE.  Configurations in DefectDojo\n  Click 'Configuration' from the left hand menu.\n  Click 'Google Sheets Sync'.\n  Fill the form.\na. Upload the downloaded json file into the Upload Credentials file field. b. Drive Folder Id\na. Create a folder inside the Google drive of the same gmail account used to create the service account. b. Get the **client\\_email** from the downloaded json file and share the created drive folder with client\\_email giving **edit access**. c. Extract the folder id from the URL and insert it as the **Drive Folder Id**.  c. Tick the Enable Service check box. (Optional as this has no impact on the configuration, but you must set it to true inorder to use the feature. Service can be enabled or disabled at any point after the configuration using this check box) d. For each field in the finding table there are two related entries in the form. a. In the drop down, select Hide if the column needs to be hidden in the Google Sheet, else select any other option based on the length of the entry that goes under the column. b. If the column needs to be protected in the Google Sheet, tick the check box. Otherwise leave it unchecked.\n  Click 'Submit'.\n  Admin has the privilege to revoke the access given to DefectDojo to access Google Sheets and Google Drive data by simply clicking the Revoke Access button.\nUsing Google Sheets Sync Feature Before a user can export a test to a Google Spreadsheet, admin must Configure Google Sheets Sync and Enable sync feature.Depending on whether a Google Spreadsheet exists for the test or not, the User interface displayed will be different.\nIf a Google Spreadsheet does not exist for the Test:\nIf a Google Spreadsheet is already created for the Test:\nAfter creating a Google Spreadsheet, users can review and edit Finding details using the Google Sheet. If any change is done in the Google Sheet users can click the Sync Google Sheet button to get those changes into DefectDojo.\n","categories":"","description":"","excerpt":"With the Google Sheets sync feature, DefectDojo allow the users to …","ref":"/django-DefectDojo/integrations/google-sheets-sync/","tags":"","title":"Google Sheets Sync"},{"body":"This is Burp Plugin to export findings directly to Defect Dojo .\nInstallation In order for the plugin to work , you will need to have Jython set up in Burp Suite Pro . To use this plugin before it appears in the BApp Store you will need to do the following :\n Go to Extender and select the Extensions tab Click on Add , select Extension Type: to be Python and select the DefectDojoPlugin.py  Usage ","categories":"","description":"","excerpt":"This is Burp Plugin to export findings directly to Defect Dojo . …","ref":"/django-DefectDojo/integrations/burp-plugin/","tags":"","title":"Defect Dojo Burp-Plugin"},{"body":"Scopes The following scopes have to be granted.\nToken The bot token has to be chosen and put in your System Settings\n","categories":"","description":"","excerpt":"Scopes The following scopes have to be granted.\nToken The bot token …","ref":"/django-DefectDojo/integrations/slack-notifications/","tags":"","title":"Slack Notifications"},{"body":"The DefectDojo team aims to release at least once a month, on the last Tuesday. Bugfix or security releases can come at any time.\nIn doubt, GitHub Actions are the source of truth. The releases are semi-automated right now, with a DefectDojo maintainer proceeding with each major step in the release. The steps for a regular release are:\n Create the release branch from dev and prepare a PR against master (details) –\u003e A maintainer verifies and manually merges the PR Tag, issue draft release and docker build+push (details) –\u003e A maintainer massages the release-drafter notes and publishes the release A PR to merge master back to dev is created to re-align the branches (details)  Security releases PRs that relate to security issues are done through security advisories which provide a way to work privately on code without prematurely disclosing vulnerabilities.\nRelease and hotfix model Diagrams created with plantUML. Find a web-based editor for PlantUML at https://www.planttext.com.\n","categories":"","description":"","excerpt":"The DefectDojo team aims to release at least once a month, on the last …","ref":"/django-DefectDojo/contributing/branching-model/","tags":"","title":"Branching Model"},{"body":"About DefectDojo What is DefectDojo? DefectDojo is a security tool that automates application security vulnerability management. DefectDojo streamlines the application security testing process by offering features such as importing third party security findings, merging and de-duping, integration with Jira, templating, report generation and security metrics.\nWhat does DefectDojo do? While traceability and metrics are the ultimate end goal, DefectDojo is a bug tracker at its core. Taking advantage of DefectDojo's Product:Engagement model, enables traceability among multiple projects and test cycles, and allows for fine-grained reporting.\nHow does DefectDojo work? DefectDojo is based on a model that allows the ultimate flexibility in your test tracking needs.\n Working in DefectDojo starts with a Product Type. Each Product Type can have one or more Products. Each Product can have one or more Engagements. Each Engagement can have one or more Tests. Each Test can have one or more Findings.  Where to find DefectDojo? The code is open source, and available on GitHub.\nA running example is available on the demo server, using the credentials admin / defectdojo@demo#appsec. Note: The demo server is refreshed regularly and provisioned with some sample data.\n","categories":"","description":"","excerpt":"About DefectDojo What is DefectDojo? DefectDojo is a security tool …","ref":"/django-DefectDojo/","tags":"","title":"DefectDojo's Documentation"},{"body":"For more info on custom settings and use of custom settings during development, please see: settings.py documentation and extra settings\nWarning To complete   DD_AUTHORIZED_USERS_ALLOW_CHANGE: Grants Active users (e.g regular users) the ability to perform changes for the Products they are authorized. DD_AUTHORIZED_USERS_ALLOW_DELETE: Grants Active users (e.g regular users) delete powers for the Products they are authorized. DD_SITE_URL: DD_DEBUG: DD_DJANGO_METRICS_ENABLED: DD_LOGIN_REDIRECT_URL: DD_DJANGO_ADMIN_ENABLED: DD_SESSION_COOKIE_HTTPONLY: DD_CSRF_COOKIE_HTTPONLY: DD_SECURE_SSL_REDIRECT: DD_SECURE_HSTS_INCLUDE_SUBDOMAINS: DD_SECURE_HSTS_SECONDS: DD_SESSION_COOKIE_SECURE: DD_CSRF_COOKIE_SECURE: DD_SECURE_BROWSER_XSS_FILTER: DD_SECURE_CONTENT_TYPE_NOSNIFF: DD_TIME_ZONE: DD_LANG: DD_TEAM_NAME: DD_ADMINS: DD_WHITENOISE: DD_TRACK_MIGRATIONS: DD_SECURE_PROXY_SSL_HEADER: DD_TEST_RUNNER: DD_URL_PREFIX: DD_ROOT: DD_LANGUAGE_CODE: DD_SITE_ID: DD_USE_I18N: DD_USE_L10N: DD_USE_TZ: DD_MEDIA_URL: DD_MEDIA_ROOT: DDimages_URL: DDimages_ROOT: DD_CELERY_BROKER_URL: DD_CELERY_BROKER_SCHEME: DD_CELERY_BROKER_USER: DD_CELERY_BROKER_PASSWORD: DD_CELERY_BROKER_HOST: DD_CELERY_BROKER_PORT: DD_CELERY_BROKER_PATH: DD_CELERY_TASK_IGNORE_RESULT: DD_CELERY_RESULT_BACKEND: DD_CELERY_RESULT_EXPIRES: DD_CELERY_BEAT_SCHEDULE_FILENAME: DD_CELERY_TASK_SERIALIZER: DD_FORCE_LOWERCASE_TAGS: DD_FOOTER_VERSION: Optionally pass a custom version string displayed in the footer of all pages (base.html template). Defaults to the version configured in django-DefectDojo/setup.py DD_MAX_TAG_LENGTH: DD_DATABASE_ENGINE: DD_DATABASE_HOST: DD_DATABASE_NAME: DD_TEST_DATABASE_NAME: DD_DATABASE_PASSWORD: DD_DATABASE_PORT: DD_DATABASE_USER: DD_SECRET_KEY: DD_CREDENTIAL_AES_256_KEY: DD_DATA_UPLOAD_MAX_MEMORY_SIZE: DD_SOCIAL_AUTH_TRAILING_SLASH: DD_SOCIAL_AUTH_AUTH0_OAUTH2_ENABLED: DD_SOCIAL_AUTH_AUTH0_KEY: DD_SOCIAL_AUTH_AUTH0_SECRET: DD_SOCIAL_AUTH_AUTH0_DOMAIN: DD_SOCIAL_AUTH_AUTH0_SCOPE: DD_SOCIAL_AUTH_GOOGLE_OAUTH2_ENABLED: DD_SOCIAL_AUTH_GOOGLE_OAUTH2_KEY: DD_SOCIAL_AUTH_GOOGLE_OAUTH2_SECRET: DD_SOCIAL_AUTH_GOOGLE_OAUTH2_WHITELISTED_DOMAINS: DD_SOCIAL_AUTH_GOOGLE_OAUTH2_WHITELISTED_EMAILS: DD_SOCIAL_AUTH_OKTA_OAUTH2_ENABLED: DD_SOCIAL_AUTH_OKTA_OAUTH2_KEY: DD_SOCIAL_AUTH_OKTA_OAUTH2_SECRET: DD_SOCIAL_AUTH_OKTA_OAUTH2_API_URL: DD_SOCIAL_AUTH_AZUREAD_TENANT_OAUTH2_ENABLED: DD_SOCIAL_AUTH_AZUREAD_TENANT_OAUTH2_KEY: DD_SOCIAL_AUTH_AZUREAD_TENANT_OAUTH2_SECRET: DD_SOCIAL_AUTH_AZUREAD_TENANT_OAUTH2_TENANT_ID: DD_SOCIAL_AUTH_AZUREAD_TENANT_OAUTH2_RESOURCE: DD_SOCIAL_AUTH_GITLAB_OAUTH2_ENABLED: DD_SOCIAL_AUTH_GITLAB_KEY: DD_SOCIAL_AUTH_GITLAB_SECRET: DD_SOCIAL_AUTH_GITLAB_API_URL: DD_SOCIAL_AUTH_GITLAB_SCOPE: DD_SAML2_ENABLED: DD_SAML2_METADATA_AUTO_CONF_URL: DD_SAML2_METADATA_LOCAL_FILE_PATH: DD_SAML2_ASSERTION_URL: DD_SAML2_ENTITY_ID: DD_SAML2_DEFAULT_NEXT_URL: DD_SAML2_NEW_USER_PROFILE: DD_SAML2_ATTRIBUTES_MAP: DD_DISABLE_FINDING_MERGE: DD_AUTHORIZED_USERS_ALLOW_CHANGE: DD_AUTHORIZED_USERS_ALLOW_DELETE: DD_AUTHORIZED_USERS_ALLOW_STAFF: DD_SLA_NOTIFY_ACTIVE: Consider \"Active\" findings for SLA notifications. DD_SLA_NOTIFY_ACTIVE_VERIFIED_ONLY: Consider \"Active\" and \"Verified\" findings only for SLA notifications. DD_SLA_NOTIFY_WITH_JIRA_ONLY: Considers findings that have a JIRA issue linked. DD_SLA_NOTIFY_PRE_BREACH: Number of days to notify before breaching the SLA. DD_SLA_NOTIFY_POST_BREACH: Number of days to keep notifying after the SLA has been breached. DD_EMAIL_URL, default:  ","categories":"","description":"","excerpt":"For more info on custom settings and use of custom settings during …","ref":"/django-DefectDojo/running/configuration/","tags":"","title":"Configuration"},{"body":"The documentation is build with Hugo and uses the theme Docsy. The source code is located in the docs folder. Static files for the webside are build with github actions and are publish in the gh-pages branch.\nHow to run a local preview   Install Hugo. Make sure you have installed the extended version with Sass/SCSS support.\n  Clone the DefectDojo git repository with the option --recurse-submodules. If you have already cloned the repository, make sure that you have checked out out the Docsy theme or use git submodule to check it out:\ncd docs/themes/docsy git submodule update --init --recursive    Install PostCSS\nTo build or update your site’s CSS resources, you also need PostCSS to create the final assets. If you need to install it, you must have a recent version of NodeJS installed on your machine so you can use npm, the Node package manager. By default npm installs tools under the directory where you run npm install:\nsudo npm install -D autoprefixer sudo npm install -D postcss-cli  Starting in version 8 of postcss-cli, you must also separately install postcss:\nsudo npm install -D postcss    Switch to the docs folder and start the hugo server with hot reloading hugo server -D\n  Visit http://localhost:1313.\n  See also the Docsy installation procedures for reference.\n","categories":"","description":"","excerpt":"The documentation is build with Hugo and uses the theme Docsy. The …","ref":"/django-DefectDojo/contributing/documentation/","tags":"","title":"Documentation"},{"body":" Information All commands assume that you’re located at the root of the django-DefectDojo cloned repo.  Pre-requisites  You have forked https://github.com/DefectDojo/django-DefectDojo and cloned locally. Checkout dev and make sure you’re up to date with the latest changes. It’s advised that you create a dedicated branch for your development, such as git checkout -b parser-name yet that’s up to you.  It is probably easier to use the docker-compose stack (and benefit from the hot-reload capbility for uWSGI). Set up your environment to use the dev or ptvsd environment, such as:\n$ docker/setEnv.sh dev or\n# allows to set breakpoints in uWSGI $ docker/setEnv.sh ptvsd Please have a look at DOCKER.md for more details.\nDocker images You’d want to build your docker images locally, and eventually pass in your local user’s uid to be able to write to the image (handy for database migration files). Assuming your user’s uid is 1000, then:\n$ docker-compose build --build-arg uid=1000 Which files do you need to modify?    File Purpose     dojo/tools/\u003cparser_dir\u003e/__init__.py Empty file for class initialization   dojo/tools/\u003cparser_dir\u003e/parser.py The meat. This is where you write your actual parser   dojo/unittests/scans/\u003cparser_dir\u003e/{many_vulns,no_vuln,one_vuln}.json Sample files containing meaningful data for unit tests. The minimal set.    Template Generator Utilze the template parser to quickly generate the files required. To get started you will need to install cookiecutter.\n$ pip install cookiecutter Then generate your scanner parser from the root of django-DefectDojo:\n$ cookiecutter https://github.com/DefectDojo/cookiecutter-scanner-parser Read more on the template configuration variables.\nThings to pay attention to Parsers may have many fields, out of which many of them may be optional.\nAlways make sure you include checks to avoid potential KeyError errors (e.g. field does not exist), for those fields you are not absolutely certain will always be in file that will get uploaded. These translate to 500 error, and do not look good.\nUnit tests Each parser must have unit tests, at least to test for 0 vuln, 1 vuln and many vulns. You can take a look at how other parsers have them for starters. The more quality tests, the better.\nTest database To test your unit tests locally, you first need to grant some rights. Get your MySQL root password from the docker-compose logs, login as root and issue the following commands:\nMYSQL\u003e grant all privileges on test_defectdojo.* to defectdojo@'%'; MYSQL\u003e flush privileges; Run your tests This local command will launch the unit test for your new parser\n$ docker-compose exec uwsgi bash -c 'python manage.py test dojo.unittests.\u003cyour_unittest_py_file\u003e.\u003cmain_class_name\u003e -v2' Example for the blackduck hub parser:\n$ docker-compose exec uwsgi bash -c 'python manage.py test dojo.unittests.test_blackduck_csv_parser.TestBlackduckHubParser -v2' Information If you want to run all unit tests, simply run $ docker-compose exec uwsgi bash -c 'python manage.py test dojo.unittests -v2'  Other files that could be involved Change to the model In the event where you’d have to change the model, e.g. to increase a database column size to accomodate a longer string of data to be saved\n  Change what you need in dojo/models.py\n  Create a new migration file in dojo/db_migrations by running and including as part of your PR\n$ docker-compose exec uwsgi bash -c 'python manage.py makemigrations -v2'    Accept a different type of file to upload If you want to be able to accept a new type of file for your parser, take a look at dojo/forms.py around line 436 (at the time of this writing) or locate the 2 places (for import and re-import) where you find the string attrs={\"accept\":.\nFormats currently accepted: .xml, .csv, .nessus, .json, .html, .js, .zip.\nA need for more than just the parser.py Of course, nothing prevents you from having more files than the parser.py file. It’s python :-)\nExample PRs If you want to take a look at previous parsers that are now part of DefectDojo, take a look at https://github.com/DefectDojo/django-DefectDojo/pulls?q=is%3Apr+label%3A%22import+scans%22+\nUpdate the GitHub pages documentation The DefectDojo official documentation lives in the docs folder, https://github.com/DefectDojo/django-DefectDojo/tree/dev/docs Please update docs/content/en/import.md with the details of your new parser.\n","categories":"","description":"","excerpt":" Information All commands assume that you’re located at the root of …","ref":"/django-DefectDojo/contributing/how-to-write-a-parser/","tags":"","title":"How to write a DefectDojo parser"},{"body":"Production with docker-compose The docker-compose.yml file in this repository is fully functional to evaluate DefectDojo in your local environment.\nAlthough Docker Compose is one of the supported installation methods to deploy a containerized DefectDojo in a production environment, the docker-compose.yml file is not intended for production use without first customizing it to your particular situation.\nDatabase performance and backup It is recommended to use a dedicated database server and not the preconfigured MySQL database. This will improve the performance of DefectDojo\nIn both case, if you use a dedicated database server or if you should decide to use the preconfigured MySQL database, make sure to make regular backups of the data. For a dedicated database server follow the instructions that come with the database server. For the preconfigured MySQL you can use mysqldump, e.g. as described in How to backup a Docker MySQL database.\nBackup of Media files Media files for uploaded files, including threat models and risk acceptance, are stored in a docker volume. This volume needs to be backed up regularly.\nInstance size Information Please read the paragraphs below about key processes tweaks.  Having taken the database to run elsewhere, the minimum recommendation is:\n 2 vCPUs 8 GB of RAM 2 GB of disk space (remember, your database is not here -- so basically, what you have for your O/S should do). You could allocate a different disk than your OS's for potential performance improvements.  Key processes Per https://github.com/DefectDojo/django-DefectDojo/pull/2813, it is now easy to somewhat improve the uWSGI and celery worker performance.\nuWSGI By default (except in ptvsd mode for debug purposes), uWSGI will handle 4 concurrent connections.\nBased on your resource settings, you can tweak:\n DD_UWSGI_NUM_OF_PROCESSES for the number of spawned processes. (default 2) DD_UWSGI_NUM_OF_THREADS for the number of threads in these processes. (default 2)  For example, you may have 4 processes with 6 threads each, yielding 24 concurrent connections.\nCelery worker By default, a single mono-process celery worker is spawned. This is fine until you start having many findings, and when async operations like deduplication start to kick in. Eventually, it will starve your resources and crawl to a halt, while operations continue to queue up.\nThe following variables will help a lot, while keeping a single celery worker container.\n DD_CELERY_WORKER_POOL_TYPE will let you switch to prefork. (default solo)  As you've enabled prefork, the following variables have to be used. The default are working fairly well, see the Dockerfile.django for in-file references.\n DD_CELERY_WORKER_AUTOSCALE_MIN defaults to 2. DD_CELERY_WORKER_AUTOSCALE_MAX defaults to 8. DD_CELERY_WORKER_CONCURRENCY defaults to 8. DD_CELERY_WORKER_PREFETCH_MULTIPLIER defaults to 128.  You can execute the following command to see the configuration:\ndocker-compose exec celerybeat bash -c \"celery -A dojo inspect stats\" and see what is in effect.\nMonitoring To expose Django statistics for Prometheus, using the text-editor of your choice, change DJANGO_METRICS_ENABLED to True in django-DefectDojo/dojo/settings/settings.py to:\n`DJANGO_METRICS_ENABLED = True` Or export DD_DJANGO_METRICS_ENABLED with the same value.\nPrometheus endpoint than is available under the path: http://dd_server/django_metrics/metrics\n","categories":"","description":"","excerpt":"Production with docker-compose The docker-compose.yml file in this …","ref":"/django-DefectDojo/running/running-in-production/","tags":"","title":"Running in Production"},{"body":"Docker-compose When you deploy a vanilla docker-compose, it will create a persistent volume for your MySQL database. As long as your volume is there, you should not lose any data.\nUsing docker images provided in DockerHub Information If you're using latest, then you need to pre pull the latest from DockerHub to update.  The generic upgrade method for docker-compose follows these steps:\n  Pull the latest version\ndocker pull defectdojo/defectdojo-django:latest docker pull defectdojo/defectdojo-nginx:latest   If you would like to use something older (so not the latest version), specify the version (tag) you want to upgrade to:\ndocker pull defectdojo/defectdojo-django:1.10.2 docker pull defectdojo/defectdojo-nginx:1.10.2   Go to the directory where your docker-compose.yml file lives\n  Stop DefectDojo: docker-compose stop\n  Re-start DefectDojo, allowing for container recreation: docker-compose up -d\n  Run the database migrations to bring your database schema up to speed with the latest code\n  If you have the initializer disabled (or if you want to be on the safe side), run the migration command: docker-compose exec uwsgi /bin/bash -c 'python manage.py migrate\n  Building your local images If you build your images locally and do not use the ones from DockerHub, the instructions are much the same, except that you'd build your images first. (Of course, if you're doing this, then you know you have to update the source code first)\nReplace the first step above with this one: - docker-compose build\nUpgrading to DefectDojo Version 2.0.x. WARNING: Upgrade to 1.15.x first before upgrading to 2.0.0, otherwise you will brick you instance.\nWARNING: Run docker-compose exec uwsgi ./manage.py endpoint_pre-migration_check before upgrading to check if your endpoints can be migrated succesfully. (#4188)\nWe decided to name this version 2.0.0 because we did some big cleanups in this release:\n  Remove API v1 (#4413)\n  Remove setup.bash installation method (#4417)\n  Rename Finding.is_Mitigated field to Finding.is_mitigated (#3854)\n  Remove everything related to the old tagging library (#4419)\n  Remove S0/S1/S2../S5 severity display option (#4415)\n  Refactor EndPoint handling/formatting (#4188)\n  Upgrade to Django 3.x (#3632)\n  PDF Reports removed (#4418)\n  See release notes: https://github.com/DefectDojo/django-DefectDojo/releases/tag/2.0.0\n  Hashcode calculation logic has changed. To update existing findings run:\n./manage.py dedupe --hash_code_only\n  If you’re using docker:\n`docker-compose exec uwsgi ./manage.py dedupe --hash_code_only`  This can take a while depending on your instance size.\nUpgrading to DefectDojo Version 1.15.x   See release notes: https://github.com/DefectDojo/django-DefectDojo/releases/tag/1.15.0\n  If you have made changes to JIRA templates or the template config in the JIRA Project config for instances/products/engagements: The jira template settings introduced in 1.13 have been changed. You now have to select a subfolder instead of a sinlge template file. If you have chosen a non-default template here, you have to reapply that to all products / engagements. Also you have to move your custom templates into the correct subfolder in dojo/templates/issue-trackers/.\n  Hashcode calculation logic has changed in #4134, #4308 and #4310 to update existing findings run:\n./manage.py dedupe --hash_code_only\n  If you’re using docker:\ndocker-compose exec uwsgi ./manage.py dedupe --hash_code_only\nThis can take a while depending on your instance size.\nUpgrading to DefectDojo Version 1.14.x  See release notes: https://github.com/DefectDojo/django-DefectDojo/releases/tag/1.14.0  Note that the below fields are now optional without default value. They will not be filled anymore with values such as “No references given” when found empty while saving the findings\n mitigation references impact url  Upgrading to DefectDojo Version 1.13.x   See release notes: https://github.com/DefectDojo/django-DefectDojo/releases/tag/1.13.0\n  Hashcode settings affecting deduplication have changed, to update existing findings run:\n./manage.py dedupe\n  If you’re using docker:\ndocker-compose exec uwsgi ./manage.py dedupe  This can take a while depeneding on your instance size. It might possible that new duplicates are detected among existing findings, so make a backup before running!\nUpgrading to DefectDojo Version 1.12.x  See release notes: https://github.com/DefectDojo/django-DefectDojo/releases/tag/1.12.0 1.12.1 is a security release https://github.com/DefectDojo/django-DefectDojo/releases/tag/1.12.1  Upgrading to DefectDojo Version 1.11.x  See release notes: https://github.com/DefectDojo/django-DefectDojo/releases/tag/1.11.0 1.11.1 is a security release https://github.com/DefectDojo/django-DefectDojo/releases/tag/1.11.1  Upgrading to DefectDojo Version 1.10.x 1.10.4 is a security release\n See the security advisory: https://github.com/DefectDojo/django-DefectDojo/security/advisories/GHSA-96vq-gqr9-vf2c See release notes: https://github.com/DefectDojo/django-DefectDojo/releases/tag/1.10.4 Version 1.10.4 replaces 1.10.3 as the latter contained an incomplete fix  What's New:\n See release notes: https://github.com/DefectDojo/django-DefectDojo/releases Defect Dojo now provides a settings.py file out-of-the-box. Custom settings need to go into local\\_settings.py. See https://github.com/DefectDojo/django-DefectDojo/blob/master/dojo/settings/settings.py and https://github.com/DefectDojo/django-DefectDojo/blob/master/docker/extra_settings/README.md A quickfix is to rename your own / customized settings.py or settings.dist.py to local\\_settings.py. Details of that PR: https://github.com/DefectDojo/django-DefectDojo/pull/3136 Major JIRA integration refactoring, for which you should at least use 1.10.1 and not 1.10.0 for many bug fixes.  Breaking changes\nKubernetes/Helm users: we have moved away from the \"stable\" repository to \"bitnami\" in this release. The bitnami postgresql chart required us to add a new key to the postgresql secret, which will give you the error postgresql-postgres-password is missing if you have createPostgresqlSecret: false. In 1.10.1, a fix was also included to allow your existing postgresqlPassword to be reused properly.\nIncluding in 1.10.1 were a couple fixes related to a rabbitMQ upgrade. The path to access password, erlangCookie and existingPasswordSecret changed from rabbitmq to auth. Furthermore, as rabbitMQ is deployed as a StatefulSet, an in-place upgrade is not possible and an error will likely be thrown such as Forbidden: updates to statefulset spec for fields other than 'replicas', 'template', and 'updateStrategy' are forbidden. After ensuring your rabbitMQ celery queue is empty, you will then want to delete your rabbitMQ StatefulSet and PVC to allow them to get re-created, or fully delete and recreate defectdojo.\nUpgrading to DefectDojo Version 1.9.3 This is a security release\n See the security advisory See release notes  What's New:\n See release notes: https://github.com/DefectDojo/django-DefectDojo/releases  NOTE:\nWhen upgrading from before 1.9.2, a corrective script may need to be ran\n./manage.py create\\_endpoint\\_status\nIf you're using docker:\ndocker-compose exec uwsgi ./manage.py create\\_endpoint\\_status\nThis can take a while depending on your hardware and the number of findings in your instance.\n Search index tweaking index rebuild after upgrade:  This requires a (one-time) rebuild of the Django-Watson search index. Execute the django command from the defect dojo installation directory:\n./manage.py buildwatson]\nIf you're using docker:\ndocker-compose exec uwsgi ./manage.py buildwatson\nThis can take a while depending on your hardware and the number of findings in your instance.\nUpgrading to DefectDojo Version 1.8.0 What's New:\n See release notes: https://github.com/DefectDojo/django-DefectDojo/releases Improved search, which requires an index rebuild (https://github.com/DefectDojo/django-DefectDojo/pull/2861)  This requires a (one-time) rebuild of the Django-Watson search index. Execute the django command from the defect dojo installation directory:\n./manage.py buildwatson\nIf you're using docker:\ndocker-compose exec uwsgi ./manage.py buildwatson\nThis can take a while depending on your hardware and the number of findings in your instance.\n NOTE:  As a result of a breaking bug revolving around Endpoint_status objects, a corrective script will need to be ran after every dynamic scan imported through either API version.\nThe script can be found here\n./manage.py create\\_endpoint\\_status\nIf you're using docker:\ndocker-compose exec uwsgi ./manage.py create\\_endpoint\\_status\nThis can take a while depending on your hardware and the number of findings in your instance.\nUpgrading to DefectDojo Version 1.7.0 What's New:\n Updated search, you can now search for CVE-XXXX-YYYY Updated search index, fields added to index: 'id', 'title', 'cve', 'url', 'severity', 'description', 'mitigation', 'impact', 'steps_to_reproduce', 'severity_justification', 'references', 'sourcefilepath', 'sourcefile', 'hash_code', 'file_path', 'component_name', 'component_version', 'unique_id_from_tool'  This requires a (one-time) rebuild of the Django-Watson search index. Execute the django command from the defect dojo installation directory:\n./manage.py buildwatson dojo.Finding\nIf you're using docker:\ndocker-compose exec uwsgi ./manage.py buildwatson dojo.Finding\nUpgrading to DefectDojo Version 1.5.0 What's New:\n Updated UI with a new DefectDojo logo, default colors and CSS. Updated Product views with tabs for Product Overview, Metrics, Engagements, Endpoints, Benchmarks (ASVS), and Settings to make it easier to navigate and manage your products. New Product Information fields: Regulations, Criticality, Platform, Lifecycle, Origin, User Records, Revenue, External Audience, Internet Accessible Languages pie chart on product overview, only supported through the API and Django admin, integrates with cloc analyzer New Engagement type of CI/CD to support continual testing Engagement shortcuts and ability to import findings and auto-create an engagement Engagement labels for overdue, no tests and findings New Contextual menus throughout DefectDojo and shortcuts to new findings and critical findings Ability to merge a finding into a parent finding and either inactivate or delete the merged findings. Report improvements and styling adjustment with the default option of HTML reports SLA for remediation of severities based on finding criticality, for example critical findings remediated within 7 days. Configurable in System Settings. Engagement Auto-Close Days in System Settings. Automatically close an engagement if open past the end date. Ability to apply remediation advice based on CWE. For example XSS can be configured as a template so that it's consistent across all findings. Enabled in system settings. Finding confidence field supported from scanners. First implementation in the Burp importer. Goast importer for static analysis of Golang products Celery status check on System Settings Beta rules framework release for modifying findings on the fly DefectDojo 2.0 API with Swagger support Created and Modified fields on all major tables Various bug fixes reported on Github  Upgrading to 1.5.0 requirements:\n  Back up your database first, ideally take the backup from production and test the upgrade on a staging server.\n  Edit the settings.py file which can be found in django-DefectDojo/dojo/settings/settings.py. Copy in the rest framework configuration after the CSRF_COOKIE_SECURE = True:\nREST_FRAMEWORK = { 'DEFAULT_AUTHENTICATION_CLASSES': ( 'rest_framework.authentication.TokenAuthentication', 'rest_framework.authentication.BasicAuthentication', ), 'DEFAULT_PERMISSION_CLASSES': ( 'rest_framework.permissions.DjangoModelPermissions', ), 'DEFAULT_RENDERER_CLASSES': ( 'rest_framework.renderers.JSONRenderer', ), 'DEFAULT_PAGINATION_CLASS': 'rest_framework.pagination.LimitOffsetPagination', 'PAGE_SIZE': 25 }    Navigate to: LOGIN_EXEMPT_URLS and add the following after r'^%sfinding/image/(?P\u003ctoken\u003e[^/]+)$' % URL_PREFIX:\nr'^%sfinding/image/(?P\u003ctoken\u003e[^/]+)$' % URL_PREFIX, r'^%sapi/v2/' % URL_PREFIX,  Navigate to: INSTALLED_APPS and add the following after: 'multiselectfield',:\n'multiselectfield', 'rest_framework', 'rest_framework.authtoken', 'rest_framework_swagger', 'dbbackup',  Navigate to: CELERY_TASK_IGNORE_RESULT = True and add the following after CELERY_TASK_IGNORE_RESULT line:\nCELERY_RESULT_BACKEND = 'db+sqlite:///dojo.celeryresults.sqlite'  Save your modified settings file. For reference the modified file should look like the new 1.5.0 [settings](https://github.com/DefectDojo/django-DefectDojo/blob/master/dojo/settings/settings.dist.py) file, minus the environmental configurations. As an alternative this file can be used and the enviromental configurations from you environment can be copied into this file.\nActivate your virtual environment and then upgrade the requirements:  pip install -r requirements.txt --upgrade\n Upgrade the database:\n./manage.py makemigrations ./manage.py migrate    Collect the static files (Javascript, Images, CSS):\n./manage.py collectstatic --noinput    Complete\n  Upgrading to DefectDojo Version 1.3.1 What's New:\n New importers for Contrast, Nikto and TruffleHog (finding secrets in git repos). Improved merging of findings for dynamic and static importers Markdown support for findings HTML report improvements including support of Markdown. System settings Celery status page to assist in debugging if Celery is functional.  Upgrading to 1.3.1 requires:\n pip install markdown pip install pandas ./manage.py makemigrations ./manage.py migrate ./manage.py collectstatic --noinput Complete  Upgrading to DefectDojo Version 1.2.9 What's New: New feature: Benchmarks (OWASP ASVS)\nUpgrading to 1.2.9 requires:\n ./manage.py makemigrations ./manage.py migrate ./manage.py loaddata dojo/fixtures/benchmark_type.json ./manage.py loaddata dojo/fixtures/benchmark_category.json ./manage.py loaddata dojo/fixtures/benchmark_requirement.json ./manage.py collectstatic --noinput Complete  Upgrading to DefectDojo Version 1.2.8 New feature: Product Grading (Overall Product Health) Upgrading to 1.2.8 requires:\n ./manage.py makemigrations ./manage.py migrate ./manage.py system_settings ./manage.py collectstatic --noinput pip install asteval pip install --upgrade celery Complete  Upgrading to DefectDojo Version 1.2.4 Upgrading to 1.2.4 requires:\n ./manage.py makemigrations ./manage.py migrate ./manage.py loaddata dojo/fixtures/objects_review.json  Upgrading to DefectDojo Version 1.2.3 Upgrading to 1.2.3 requires:\n ./manage.py makemigrations ./manage.py migrate ./manage.py loaddata dojo/fixtures/language_type.json Currently languages and technologies can be updated via the API or in the admin section of Django.  July 6th 2017 - New location for system settings Pull request #313 moves a number of system settings previously located in the application's settings.py to a model that can be used and changed within the web application under \"Configuration -\u003e System Settings\".\nIf you're using a custom URL_PREFIX you will need to set this in the model after upgrading by editing dojo/fixtures/system_settings.json and setting your URL prefix in the url_prefix value there. Then issue the command ./manage.py loaddata system_settings.json to load your settings into the database.\nIf you're not using a custom URL_PREFIX, after upgrading simply go to the System Settings page and review which values you want to set for each setting, as they're not automatically migrated from settings.py.\nIf you like you can then remove the following settings from settings.py to avoid confusion:\n ENABLE_DEDUPLICATION ENABLE_JIRA S_FINDING_SEVERITY_NAMING URL_PREFIX TIME_ZONE TEAM_NAME  Upgrading to DefectDojo Version 1.2.2 Upgrading to 1.2.2 requires:\n Copying settings.py to the settings/ folder. If you have supervisor scripts change DJANGO_SETTINGS_MODULE=dojo.settings.settings  Upgrading to Django 1.1.5 If you are upgrading an existing version of DefectDojo, you will need to run the following commands manually:\n  First install Yarn. Follow the instructions based on your OS: https://yarnpkg.com/lang/en/docs/install/\n  The following must be removed/commented out from settings.py: :\n'djangobower.finders.BowerFinder', From the line that contains: # where should bower install components ... To the end of the bower declarations 'justgage' )    The following needs to be updated in settings.py: :\nSTATICFILES_DIRS = ( # Put strings here, like \"/home/html/static\" or \"C:/www/django/static\". # Always use forward slashes, even on Windows. # Don't forget to use absolute paths, not relative paths. os.path.dirname(DOJO_ROOT) + \"/components/yarn_components\", )    Upgrading to Django 1.11 Pull request #300 makes DefectDojo Django 1.11 ready. A fresh install of DefectDojo can be done with the setup.bash script included - no special steps are required.\nIf you are upgrading an existing installation of DefectDojo, you will need to run the following commands manually: :\npip install django-tastypie --upgrade pip install django-tastypie-swagger --upgrade pip install django-filter --upgrade pip install django-watson --upgrade pip install django-polymorphic --upgrade pip install django --upgrade pip install pillow --upgrade ./manage.py makemigrations ./manage.py migrate  The following must be removed/commented out from settings.py: :\nTEMPLATE_DIRS TEMPLATE_DEBUG TEMPLATE_LOADERS TEMPLATE_CONTEXT_PROCESSORS  The following needs to be added to settings.py: :\nTEMPLATES = [ { 'BACKEND': 'django.template.backends.django.DjangoTemplates', 'APP_DIRS': True, 'OPTIONS': { 'context_processors': [ 'django.template.context_processors.debug', 'django.template.context_processors.request', 'django.contrib.auth.context_processors.auth', 'django.contrib.messages.context_processors.messages', ], }, }, ]  Once all these steps are completed your installation of DefectDojo will be running under Django 1.11\n","categories":"","description":"","excerpt":"Docker-compose When you deploy a vanilla docker-compose, it will …","ref":"/django-DefectDojo/running/upgrading/","tags":"","title":"Upgrading"},{"body":"DefectDojo is designed to make tracking testing engagements simple and intuitive. The models{.interpreted-text role=“doc”} page will help you understand the terminology we use below, so we recommend taking a look at that first.\nCreate a new Product Type The first step to using DefectDojo is to create a Product Type. Some examples might be \"Mobile Apps\" or \"New York Office.\" The idea is to make it easy to divide your Products into logical categories, based on your organizational structure, or just to divide internal and external applications.\nSelect \"View Product Types\" from the \"Products\" dropdown in the main menu.\nClick the \"New Product Type\" button at the top.\nEnter a name for your new Product Type.\nCreate a new Test Type Test Types will help you differentiate the scope of your work. For instance, you might have a Performance Test Type, or a specific type of security testing that you regularly perform.\nSelect \"Test Types\" from the \"Engagements\" dropdown in the main menu.\nClick the \"New Test Type\" button at the top.\nEnter a name for your new Test Type.\nCreate a new Development Environment Development Environments are for tracking distinct deployments of a particular Product. You might have one called \"Local\" if you deploy the Product on your own computer for testing, or \"Staging\" or \"Production\" for official deployments.\nSelect \"Development Environments\" from the \"Engagements\" dropdown in the main menu.\nClick the \"New Development Environment\" button at the top.\nEnter a name for your new Development Environment.\nCreate a new Engagement Engagements are useful for tracking the time spent testing a Product. They are associated with a Product, a Testing Lead, and are comprised of one or more Tests that may have Findings associated with them. Engagements also show up on your calendar.\nSelect \"Engagements\" from the \"Engagements\" dropdown in the main menu.\nClick the \"New Engagement\" button on the right.\nEnter the details of your Engagement.\nThe Deduplication Level specifies weather to perform deduplication only for tests in the engagement or to perform deduplication on all tests in the product which have an engagement also on Deduplication Level product. Enabled deduplication is mandatory.\nAdding Tests to an Engagement From the Engagement creation page, you can add a new Test to the Engagement. You can also add a Test to the Engagement later from that Engagement's main page. Tests are associated with a particular Test Type, a time, and an Environment.\nEnter the details of your Test.\nAdding Findings to a Test Findings are the defects or interesting things that you want to keep track of when testing a Product during a Test/Engagement. Here, you can lay out the details of what went wrong, where you found it, what the impact is, and your proposed steps for mitigation. You can also reference CWEs, or add links to your own references.\nTemplating findings allows you to create a version of a finding that you can then re-use over and over again, on any Engagement.\nEnter the details of your Finding, or click the \"Add Finding from Template\" button to use a templated Finding.\nFrom the \"Add Finding Template\" popup, you can select finding templates from the list, or use the search bar. Templates can be used across all Engagements.\nDefine what kind of Finding this is. Is it a false positive? A duplicate? If you want to save this finding as a template, check the \"Is template\" box.\nAccepting a Finding Risk Findings cannot always be remediated or addressed for various reasons. A finding status can change to accepted by doing the following. Findings are accepted in the engagement view. To locate the engagement from the finding click the link to engagement as shown below.\nThen, in the engagement view click the plus icon in the 'Risk Acceptance' box and fill in the details to support the risk acceptance.\nThe engagement view is now updated with the risk.\nThe finding status changes to 'Accepted' with a link to the risk acceptance.\nViewing an Engagement Most of the work of an Engagement can be done from that Engagement's main page. You can view the Test Strategy or Threat Model, modify the Engagement dates, view Tests and Findings, add Risk Acceptance, complete the security Check List, or close the Engagement.\nThis page lets you do most of the common tasks that are associated with an Engagement.\nTracking your Engagements in the calendar The calendar can help you keep track of what Engagements your team is currently working on, or determine the time line for past Engagements.\nSelect \"Calendar\" in the main menu.\nHere you can view the current engagements for the month, or go back in time.\nTracking metrics for your Products Tracking metrics for your Products can help you identify Products that may need additional help, or highlight a particularly effective member of your team.\nYou can also see the Dashboard view, a page that scrolls automatically, showing off the results of your testing. This can be useful if you want to display your team's work in public without showing specific details.\nSelect \"All\" or a Product Type from the \"Metrics\" drop-down in the main menu.\nHere you can see graphs of various metrics, with the ability to filter your results by time, Product Type, and severity.\nAt the bottom of the Metrics page, you can see granular data about your work, such as a breakdown of the most severe bugs by Product, lists of open, accepted, and closed Findings, and trends for each week, as well as the age of all current open Findings.\n","categories":"","description":"","excerpt":"DefectDojo is designed to make tracking testing engagements simple and …","ref":"/django-DefectDojo/basics/start-using/","tags":"","title":"Usage Examples"}]